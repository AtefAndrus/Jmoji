# Jmoji v4データセット生成設定
# ベース: default.yaml
# 変更点: max_samples=20000, random_seed=43, 出力ファイル名

# =============================================================================
# データ生成設定
# =============================================================================
data:
  # Wikipediaデータセット
  wikipedia_subset: "20231101.ja"
  wikipedia_dataset: "wikimedia/wikipedia"

  # サンプリング設定（v4用に変更）
  max_samples: 20000       # 5000 → 20000
  random_seed: 43          # 42 → 43（v4用）

  # テキストフィルタリング
  min_text_length: 10
  max_text_length: 100

  # NSFWコンテンツフィルタ
  nsfw_filter:
    enabled: true
    keywords:
      # 性的コンテンツ
      - "性行為"
      - "性交"
      - "ポルノ"
      - "アダルト"
      - "風俗"
      - "売春"
      - "淫行"
      # 暴力的コンテンツ
      - "殺人"
      - "虐殺"
      - "拷問"
      - "処刑"
      - "惨殺"

  # 出力パス（v4用に変更）
  output_dir: "data/outputs"
  output_filename: "dataset_v4.jsonl"
  filter_log_filename: "filtered_sentences_v4.jsonl"

  # 件数保証設定
  buffer_ratio: 1.3

  # 文の完全性フィルタ
  complete_sentence_filter: true

  # 進捗表示設定
  checkpoint_interval: 500   # 20k用に調整
  preview_interval: 200      # 20k用に調整

# =============================================================================
# 教師LLM設定（Qwen3-235B-A22B via OpenRouter）
# =============================================================================
teacher:
  model: "qwen/qwen3-235b-a22b-2507"
  base_url: "https://openrouter.ai/api/v1"

  # 生成パラメータ（Shisa.AI推奨）
  temperature: 0.2
  max_tokens: 100
  min_p: 0.1

  # レート制限対策
  request_delay: 0.3
  max_retries: 3
  timeout: 60

  # 並列リクエスト設定（非同期モード）
  use_async: true            # 非同期モード有効
  max_concurrent: 10

# =============================================================================
# 絵文字設定
# =============================================================================
emoji:
  min_count: 1
  max_count: 5
  normalize_skin_tone: true
  exclude_flags: false
  exclude_symbols: false

# =============================================================================
# T5学習設定（生成時は使用しないが互換性のため保持）
# =============================================================================
training:
  model_name: "sonoisa/t5-base-japanese"
  train_ratio: 0.8
  val_ratio: 0.1
  test_ratio: 0.1
  batch_size: 16
  learning_rate: 0.001
  weight_decay: 0.01
  num_epochs: 10
  warmup_steps: 500
  max_input_length: 128
  max_output_length: 32
  early_stopping_patience: 3
  metric_for_best_model: "eval_loss"
  fp16: true
  gradient_accumulation_steps: 1
  logging_steps: 100
  save_strategy: "epoch"
  output_dir: "outputs/models"

# =============================================================================
# 評価設定
# =============================================================================
evaluation:
  metrics:
    - jaccard
    - f1_micro
    - f1_macro
    - exact_match
    - length_correlation
  human_eval_samples: 50
  results_dir: "outputs/evaluation"

# =============================================================================
# ロギング設定
# =============================================================================
logging:
  level: "INFO"
  format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  log_dir: "outputs/logs"
