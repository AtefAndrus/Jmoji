{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29879d88",
   "metadata": {},
   "source": [
    "# Jmoji T5 Inference Notebook\n",
    "\n",
    "HuggingFace Hubから学習済みモデルをロードして絵文字予測を行うノートブック"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b83e6f2d",
   "metadata": {},
   "source": [
    "## 1. 環境セットアップ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530708c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveをマウント（結果保存用）\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8302ac96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# リポジトリクローン\n",
    "!git clone https://github.com/AtefAndrus/Jmoji.git\n",
    "%cd /content/Jmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca4ee38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 依存関係インストール\n",
    "!pip install -q ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22485e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU確認\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b78b8b4",
   "metadata": {},
   "source": [
    "## 2. 設定\n",
    "\n",
    "使用するモデルを選択する。\n",
    "\n",
    "| モデル | Jaccard | 多様性 | 特徴 |\n",
    "|--------|---------|--------|------|\n",
    "| v4_focal_top50 | 0.182 | 14% | 精度最良 |\n",
    "| v4_top50 | 0.165 | 21% | バランス型 |\n",
    "| v4_focal_top100 | 0.115 | 25% | 多様性最良 |\n",
    "| v4_top100 | 0.120 | 21% | 標準 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28bb8b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# =============================================================================\n",
    "# 設定（ここを変更してモデルを切り替える）\n",
    "# =============================================================================\n",
    "\n",
    "# HuggingFace Hub認証トークン（プライベートリポジトリ用）\n",
    "# Colab Secrets または直接入力\n",
    "try:\n",
    "    from google.colab import userdata\n",
    "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "except:\n",
    "    HF_TOKEN = None  # 環境変数から取得される\n",
    "\n",
    "if HF_TOKEN:\n",
    "    os.environ[\"HF_TOKEN\"] = HF_TOKEN\n",
    "    print(\"HF_TOKEN loaded from Colab Secrets\")\n",
    "else:\n",
    "    print(\"Warning: HF_TOKEN not found. Set it in Colab Secrets or environment variable.\")\n",
    "\n",
    "# モデル選択\n",
    "MODEL_A_REPO = \"AtefAndrus/jmoji-t5-v4_focal_top50_20251224\"  # 精度重視\n",
    "MODEL_B_REPO = \"AtefAndrus/jmoji-t5-v4_top50_20251224\"        # バランス型\n",
    "\n",
    "# 出力設定\n",
    "OUTPUT_DIR = \"/content/Jmoji/outputs/human_eval\"\n",
    "DRIVE_OUTPUT_DIR = \"/content/drive/MyDrive/school/ai_application/human_eval\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfd6452",
   "metadata": {},
   "source": [
    "## 3. モデルロード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9009f6db",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "from src.models.t5_trainer import load_model_from_hub, generate_emoji\n",
    "\n",
    "print(\"Loading Model A (focal_top50)...\")\n",
    "tokenizer_a, model_a = load_model_from_hub(MODEL_A_REPO)\n",
    "device = str(next(model_a.parameters()).device)\n",
    "print(f\"Model A loaded on {device}\")\n",
    "\n",
    "print(\"\\nLoading Model B (top50)...\")\n",
    "tokenizer_b, model_b = load_model_from_hub(MODEL_B_REPO)\n",
    "print(f\"Model B loaded on {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7744777",
   "metadata": {},
   "source": [
    "## 4. インタラクティブ推論\n",
    "\n",
    "任意のテキストを入力して絵文字を予測する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85b43a28",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def predict_emoji(text: str, use_model_a: bool = True, use_sampling: bool = True) -> str:\n",
    "    \"\"\"テキストから絵文字を予測する。\"\"\"\n",
    "    if use_model_a:\n",
    "        return generate_emoji(model_a, tokenizer_a, text, use_sampling=use_sampling, device=device)\n",
    "    else:\n",
    "        return generate_emoji(model_b, tokenizer_b, text, use_sampling=use_sampling, device=device)\n",
    "\n",
    "def compare_models(text: str) -> None:\n",
    "    \"\"\"2つのモデルの予測を比較する。\"\"\"\n",
    "    pred_a = predict_emoji(text, use_model_a=True)\n",
    "    pred_b = predict_emoji(text, use_model_a=False)\n",
    "    print(f\"入力: {text}\")\n",
    "    print(f\"Model A (focal_top50): {pred_a}\")\n",
    "    print(f\"Model B (top50):       {pred_b}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edebb44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# テスト\n",
    "test_texts = [\n",
    "    \"今日は楽しかった\",\n",
    "    \"明日は雨らしい\",\n",
    "    \"新しいプロジェクトを始めた\",\n",
    "    \"美味しいラーメンを食べた\",\n",
    "    \"友達と映画を見た\",\n",
    "    \"仕事が忙しい\",\n",
    "]\n",
    "\n",
    "print(\"=== モデル比較 ===\\n\")\n",
    "for text in test_texts:\n",
    "    compare_models(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad890c08",
   "metadata": {},
   "source": [
    "## 5. バッチ推論（テストセットから50件）\n",
    "\n",
    "人手評価用のサンプルを生成する。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b499db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "import random\n",
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from src.evaluation.metrics import jaccard_similarity\n",
    "\n",
    "# データセットロード\n",
    "print(\"Loading dataset from HuggingFace Hub...\")\n",
    "dataset = load_dataset(\n",
    "    \"AtefAndrus/jmoji-dataset\",\n",
    "    data_files=\"data/v4.jsonl\",\n",
    "    split=\"train\",\n",
    ")\n",
    "print(f\"Total samples: {len(dataset)}\")\n",
    "\n",
    "# Top-50絵文字でフィルタリング（v4_top50モデルと同じ条件）\n",
    "from collections import Counter\n",
    "\n",
    "# 絵文字頻度を計算\n",
    "emoji_counter = Counter()\n",
    "for sample in dataset:\n",
    "    emojis = sample[\"emoji_string\"].split()\n",
    "    emoji_counter.update(emojis)\n",
    "\n",
    "top_50_emojis = set([emoji for emoji, _ in emoji_counter.most_common(50)])\n",
    "print(f\"Top 50 emojis: {len(top_50_emojis)}\")\n",
    "\n",
    "# Top-50のみを含むサンプルをフィルタ\n",
    "def is_top50_only(sample):\n",
    "    emojis = set(sample[\"emoji_string\"].split())\n",
    "    return emojis.issubset(top_50_emojis)\n",
    "\n",
    "filtered_samples = [s for s in dataset if is_top50_only(s)]\n",
    "print(f\"Filtered samples (top50 only): {len(filtered_samples)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f1b3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# サンプリング\n",
    "MAX_SAMPLES = 50\n",
    "SEED = 42\n",
    "\n",
    "random.seed(SEED)\n",
    "test_samples = random.sample(filtered_samples, min(MAX_SAMPLES, len(filtered_samples)))\n",
    "print(f\"Selected {len(test_samples)} samples for evaluation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cd9b05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 両モデルで推論\n",
    "print(\"\\n=== Model A 推論 ===\")\n",
    "results_a = []\n",
    "for i, sample in enumerate(test_samples):\n",
    "    text = sample[\"sns_text\"]\n",
    "    gold = sample[\"emoji_string\"]\n",
    "    pred = generate_emoji(model_a, tokenizer_a, text, use_sampling=True, device=device)\n",
    "\n",
    "    gold_set = set(gold.split())\n",
    "    pred_set = set(pred.split())\n",
    "    jacc = jaccard_similarity(pred_set, gold_set)\n",
    "\n",
    "    results_a.append({\n",
    "        \"text\": text,\n",
    "        \"gold\": gold,\n",
    "        \"pred\": pred,\n",
    "        \"jaccard\": jacc,\n",
    "    })\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(test_samples)} samples...\")\n",
    "\n",
    "print(f\"Model A completed. Avg Jaccard: {sum(r['jaccard'] for r in results_a) / len(results_a):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d9d4394",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n=== Model B 推論 ===\")\n",
    "results_b = []\n",
    "for i, sample in enumerate(test_samples):\n",
    "    text = sample[\"sns_text\"]\n",
    "    gold = sample[\"emoji_string\"]\n",
    "    pred = generate_emoji(model_b, tokenizer_b, text, use_sampling=True, device=device)\n",
    "\n",
    "    gold_set = set(gold.split())\n",
    "    pred_set = set(pred.split())\n",
    "    jacc = jaccard_similarity(pred_set, gold_set)\n",
    "\n",
    "    results_b.append({\n",
    "        \"text\": text,\n",
    "        \"gold\": gold,\n",
    "        \"pred\": pred,\n",
    "        \"jaccard\": jacc,\n",
    "    })\n",
    "\n",
    "    if (i + 1) % 10 == 0:\n",
    "        print(f\"Processed {i + 1}/{len(test_samples)} samples...\")\n",
    "\n",
    "print(f\"Model B completed. Avg Jaccard: {sum(r['jaccard'] for r in results_b) / len(results_b):.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b606456",
   "metadata": {},
   "source": [
    "## 6. 人手評価用CSVエクスポート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bec8fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "# マージ\n",
    "merged_samples = []\n",
    "for i, (a, b) in enumerate(zip(results_a, results_b)):\n",
    "    merged_samples.append({\n",
    "        \"id\": i + 1,\n",
    "        \"text\": a[\"text\"],\n",
    "        \"gold\": a[\"gold\"],\n",
    "        \"pred_focal_top50\": a[\"pred\"],\n",
    "        \"pred_top50\": b[\"pred\"],\n",
    "        \"jaccard_focal_top50\": a[\"jaccard\"],\n",
    "        \"jaccard_top50\": b[\"jaccard\"],\n",
    "    })\n",
    "\n",
    "# ディレクトリ作成\n",
    "Path(OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# JSONL保存\n",
    "jsonl_path = Path(OUTPUT_DIR) / \"samples.jsonl\"\n",
    "with open(jsonl_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    for sample in merged_samples:\n",
    "        f.write(json.dumps(sample, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"Saved JSONL to {jsonl_path}\")\n",
    "\n",
    "# CSV保存（Googleフォーム用）\n",
    "csv_path = Path(OUTPUT_DIR) / \"samples.csv\"\n",
    "with open(csv_path, \"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "    writer = csv.DictWriter(f, fieldnames=[\"ID\", \"入力文\", \"教師出力（Gold）\", \"モデルA出力\", \"モデルB出力\"])\n",
    "    writer.writeheader()\n",
    "    for s in merged_samples:\n",
    "        writer.writerow({\n",
    "            \"ID\": s[\"id\"],\n",
    "            \"入力文\": s[\"text\"],\n",
    "            \"教師出力（Gold）\": s[\"gold\"],\n",
    "            \"モデルA出力\": s[\"pred_focal_top50\"],\n",
    "            \"モデルB出力\": s[\"pred_top50\"],\n",
    "        })\n",
    "print(f\"Saved CSV to {csv_path}\")\n",
    "\n",
    "# Markdown保存\n",
    "md_path = Path(OUTPUT_DIR) / \"samples.md\"\n",
    "with open(md_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"# 人手評価サンプル\\n\\n\")\n",
    "    f.write(f\"サンプル数: {len(merged_samples)}件\\n\\n\")\n",
    "    f.write(\"---\\n\\n\")\n",
    "    for s in merged_samples:\n",
    "        f.write(f\"## サンプル #{s['id']}\\n\\n\")\n",
    "        f.write(f\"**入力文**: {s['text']}\\n\\n\")\n",
    "        f.write(f\"**教師出力（Gold）**: {s['gold']}\\n\\n\")\n",
    "        f.write(f\"**モデルA（focal_top50）**: {s['pred_focal_top50']} (Jaccard: {s['jaccard_focal_top50']:.3f})\\n\\n\")\n",
    "        f.write(f\"**モデルB（top50）**: {s['pred_top50']} (Jaccard: {s['jaccard_top50']:.3f})\\n\\n\")\n",
    "        f.write(\"---\\n\\n\")\n",
    "print(f\"Saved Markdown to {md_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d988828",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 統計情報\n",
    "print(\"\\n=== 統計情報 ===\")\n",
    "jaccard_a = [s[\"jaccard_focal_top50\"] for s in merged_samples]\n",
    "jaccard_b = [s[\"jaccard_top50\"] for s in merged_samples]\n",
    "print(f\"Model A (focal_top50) 平均Jaccard: {sum(jaccard_a)/len(jaccard_a):.3f}\")\n",
    "print(f\"Model B (top50) 平均Jaccard: {sum(jaccard_b)/len(jaccard_b):.3f}\")\n",
    "\n",
    "a_wins = sum(1 for a, b in zip(jaccard_a, jaccard_b) if a > b)\n",
    "b_wins = sum(1 for a, b in zip(jaccard_a, jaccard_b) if b > a)\n",
    "ties = sum(1 for a, b in zip(jaccard_a, jaccard_b) if a == b)\n",
    "print(f\"\\nJaccard比較:\")\n",
    "print(f\"  Model A wins: {a_wins}\")\n",
    "print(f\"  Model B wins: {b_wins}\")\n",
    "print(f\"  Ties: {ties}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe61a1a",
   "metadata": {},
   "source": [
    "## 7. Google Driveに保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fc71396",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Driveにコピー\n",
    "Path(DRIVE_OUTPUT_DIR).mkdir(parents=True, exist_ok=True)\n",
    "for filename in [\"samples.jsonl\", \"samples.csv\", \"samples.md\"]:\n",
    "    src = Path(OUTPUT_DIR) / filename\n",
    "    dst = Path(DRIVE_OUTPUT_DIR) / filename\n",
    "    shutil.copy(src, dst)\n",
    "    print(f\"Copied to {dst}\")\n",
    "\n",
    "print(\"\\nDone! Files saved to Google Drive.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84cdac0",
   "metadata": {},
   "source": [
    "## 8. カスタムテキスト推論\n",
    "\n",
    "以下のセルでカスタムテキストを入力して推論できる。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c94a442",
   "metadata": {},
   "outputs": [],
   "source": [
    "# カスタムテキストを入力\n",
    "custom_text = \"今日は天気が良くて散歩した\"  # ここを変更\n",
    "\n",
    "print(f\"入力: {custom_text}\")\n",
    "print(f\"Model A (focal_top50): {predict_emoji(custom_text, use_model_a=True)}\")\n",
    "print(f\"Model B (top50):       {predict_emoji(custom_text, use_model_a=False)}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
