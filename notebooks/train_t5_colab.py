# %% [markdown]
# # Jmoji T5 Training on Google Colab
#
# æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆâ†’çµµæ–‡å­—ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯

# %% [markdown]
# ## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—

# %%
# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ
from google.colab import drive
drive.mount('/content/drive')

# %%
# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³
!git clone https://github.com/AtefAndrus/Jmoji.git
%cd /content/Jmoji

# %%
# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpyproject.tomlã‹ã‚‰è‡ªå‹•è§£æ±ºï¼‰
!pip install -q .

# %%
# GPUç¢ºèª
import torch
print(f"CUDA available: {torch.cuda.is_available()}")
if torch.cuda.is_available():
    print(f"Device: {torch.cuda.get_device_name(0)}")
    print(f"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB")

# %% [markdown]
# ## 2. è¨­å®š
#
# å®Ÿé¨“ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€ç•°ãªã‚‹è¨­å®šã§å­¦ç¿’ã‚’å®Ÿè¡Œã§ãã‚‹ã€‚
#
# | å®Ÿé¨“ã‚¿ã‚¤ãƒ— | èª¬æ˜ |
# |-----------|------|
# | baseline | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆlr=3e-4ï¼‰ |
# | lr1e-4 | å­¦ç¿’ç‡èª¿æ•´ï¼ˆlr=1e-4ï¼‰ |
# | top100 | Top-100çµµæ–‡å­—åˆ¶é™ |
# | lr1e-4_top100 | lr=1e-4 + Top-100åˆ¶é™ |
# | focal | Focal Lossï¼ˆÎ³=2.0ï¼‰ |

# %%
from datetime import datetime

# =============================================================================
# å®Ÿé¨“è¨­å®šï¼ˆã“ã“ã‚’å¤‰æ›´ã—ã¦å®Ÿé¨“ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ï¼‰
# =============================================================================
DATASET_VERSION = "v3"
EXPERIMENT_TYPE = "lr1e-4"  # baseline, lr1e-4, top100, lr1e-4_top100, focal, focal_top100

# =============================================================================
# å®Ÿé¨“ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè¨­å®šã®è‡ªå‹•èª¿æ•´
# =============================================================================
EXPERIMENT_DATE = datetime.now().strftime("%Y%m%d")
EXPERIMENT_NAME = f"{DATASET_VERSION}_{EXPERIMENT_TYPE}_{EXPERIMENT_DATE}"

# ãƒ‘ã‚¹è¨­å®š
HF_DATASET_REPO = "AtefAndrus/jmoji-dataset"
OUTPUT_DIR = "/content/Jmoji/outputs/models"
EXP_DIR = f"/content/Jmoji/outputs/experiments/{EXPERIMENT_NAME}"
DRIVE_EXP_DIR = f"/content/drive/MyDrive/school/ai_application/experiments/{EXPERIMENT_NAME}"

# ãƒ™ãƒ¼ã‚¹è¨­å®š
CONFIG = {
    "experiment_name": EXPERIMENT_NAME,
    "dataset_version": DATASET_VERSION,
    "experiment_type": EXPERIMENT_TYPE,
    "model_name": "sonoisa/t5-base-japanese",
    "num_epochs": 50,
    "batch_size": 16,
    "learning_rate": 3e-4,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ
    "weight_decay": 0.01,
    "warmup_steps": 150,
    "max_input_length": 128,
    "max_output_length": 32,
    "train_ratio": 0.8,
    "val_ratio": 0.1,
    "test_ratio": 0.1,
    "fp16": False,
    "logging_steps": 50,
    "label_smoothing": 0.1,
    "early_stopping_patience": 5,
    # å®Ÿé¨“å›ºæœ‰ã®è¨­å®š
    "use_focal_loss": False,
    "focal_gamma": 2.0,
    "use_top100_filter": False,
}

# å®Ÿé¨“ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè¨­å®šã®ä¸Šæ›¸ã
if "lr1e-4" in EXPERIMENT_TYPE:
    CONFIG["learning_rate"] = 1e-4
    print("Setting: learning_rate = 1e-4")

if "top100" in EXPERIMENT_TYPE:
    CONFIG["use_top100_filter"] = True
    print("Setting: Top-100 emoji filter enabled")

if "focal" in EXPERIMENT_TYPE:
    CONFIG["use_focal_loss"] = True
    CONFIG["label_smoothing"] = 0.0  # Focal Lossã¨ä½µç”¨ã—ãªã„
    print("Setting: Focal Loss enabled (gamma=2.0)")

print(f"\nExperiment: {EXPERIMENT_NAME}")
print(f"Dataset: {HF_DATASET_REPO} ({DATASET_VERSION})")
print(f"Experiment dir: {EXP_DIR}")
print("\nConfig:")
for k, v in CONFIG.items():
    print(f"  {k}: {v}")

# %% [markdown]
# ## 3. ãƒ‡ãƒ¼ã‚¿æº–å‚™

# %%
import sys
sys.path.append("/content/Jmoji")

from datasets import load_dataset

from src.models.t5_trainer import (
    EmojiDataset,
    TrainConfig,
    setup_model_with_emoji_tokens,
    build_trainer,
    build_focal_loss_trainer,
    ExperimentLoggingCallback,
    split_dataset,
    generate_emoji,
    evaluate_model,
)
from src.evaluation.metrics import (
    diversity_ratio,
    emoji_distribution,
    compute_emoji_stats,
)
from src.data.emoji_utils import filter_samples_by_top_emojis

# HuggingFace Hubã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰
hf_dataset = load_dataset(
    HF_DATASET_REPO,
    data_files=f"data/{DATASET_VERSION}.jsonl",
    split="train",
)
samples = list(hf_dataset)
print(f"Total samples: {len(samples)}")

# åˆ†å‰²
train_samples, val_samples, test_samples = split_dataset(
    samples,
    CONFIG["train_ratio"],
    CONFIG["val_ratio"]
)
print(f"Train: {len(train_samples)}, Val: {len(val_samples)}, Test: {len(test_samples)}")

# ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª
print("\nSample data:")
for i, s in enumerate(train_samples[:3]):
    print(f"  [{i}] {s['sns_text'][:50]}... -> {s['emoji_string']}")

# %% [markdown]
# ## 3.5 çµµæ–‡å­—åˆ†å¸ƒã®ç¢ºèª

# %%
# çµµæ–‡å­—çµ±è¨ˆã‚’è¨ˆç®—ï¼ˆsrc/evaluation/metrics.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
emoji_counts, total_emoji_count, unique_emoji_count = compute_emoji_stats(samples)

print(f"Total emoji occurrences: {total_emoji_count}")
print(f"Unique emojis: {unique_emoji_count}")
print("\nTop 20 emojis:")
for emoji, count in emoji_counts.most_common(20):
    pct = count / total_emoji_count * 100
    print(f"  {emoji}: {count} ({pct:.1f}%)")

# æœ€é »å‡ºçµµæ–‡å­—ã®å‰²åˆã‚’è­¦å‘Š
top_emoji, top_count = emoji_counts.most_common(1)[0]
top_pct = top_count / total_emoji_count * 100
if top_pct > 15:
    print(f"\nWarning: '{top_emoji}' is {top_pct:.1f}% of all emojis. This may cause mode collapse.")

# Top-5çµµæ–‡å­—ã‚’ä¿å­˜ï¼ˆè©•ä¾¡æ™‚ã®å¤šæ§˜æ€§æŒ‡æ¨™ã§ä½¿ç”¨ï¼‰
TOP_5_EMOJIS = set(e for e, _ in emoji_counts.most_common(5))
print(f"\nTop 5 emojis (for diversity metric): {TOP_5_EMOJIS}")

# %% [markdown]
# ## 3.6 Top-100çµµæ–‡å­—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
#
# `use_top100_filter=True` ã®å ´åˆã€Top-100çµµæ–‡å­—ã®ã¿ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã«åˆ¶é™ã™ã‚‹ã€‚

# %%
if CONFIG["use_top100_filter"]:
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆsrc/data/emoji_utils.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰
    original_count = len(samples)
    samples, emoji_counts, top_100_emojis = filter_samples_by_top_emojis(
        samples, top_n=100
    )
    print(f"Top-100 emojis: {len(top_100_emojis)}")
    print(f"Filtered samples: {len(samples)} / {original_count} ({len(samples)/original_count*100:.1f}%)")
    print(f"Unique emojis after filter: {len(emoji_counts)}")

    # åˆ†å‰²ã‚’å†å®Ÿè¡Œ
    train_samples, val_samples, test_samples = split_dataset(
        samples,
        CONFIG["train_ratio"],
        CONFIG["val_ratio"]
    )
    print(f"Train: {len(train_samples)}, Val: {len(val_samples)}, Test: {len(test_samples)}")
else:
    print("Top-100 filter: DISABLED")

# %% [markdown]
# ## 4. ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶æº–å‚™

# %%
tokenizer, model = setup_model_with_emoji_tokens(CONFIG["model_name"])
print(f"Vocab size: {len(tokenizer)}")

# çµµæ–‡å­—ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ç¢ºèª
test_emoji = "ğŸ˜Š ğŸ‰"
ids = tokenizer.encode(test_emoji, add_special_tokens=False)
decoded = tokenizer.decode(ids)
print(f"Emoji tokenization test: '{test_emoji}' -> {ids} -> '{decoded}'")

# %% [markdown]
# ## 5. Datasetæº–å‚™

# %%
# Datasetä½œæˆ
train_dataset = EmojiDataset(
    train_samples, tokenizer,
    CONFIG["max_input_length"],
    CONFIG["max_output_length"]
)
val_dataset = EmojiDataset(
    val_samples, tokenizer,
    CONFIG["max_input_length"],
    CONFIG["max_output_length"]
)
test_dataset = EmojiDataset(
    test_samples, tokenizer,
    CONFIG["max_input_length"],
    CONFIG["max_output_length"]
)

print(f"Train dataset: {len(train_dataset)}")
print(f"Val dataset: {len(val_dataset)}")
print(f"Test dataset: {len(test_dataset)}")

# ãƒ‡ãƒ¼ã‚¿ç¢ºèª
item = train_dataset[0]
print(f"\nSample item shapes:")
print(f"  input_ids: {item['input_ids'].shape}")
print(f"  attention_mask: {item['attention_mask'].shape}")
print(f"  labels: {item['labels'].shape}")
print(f"  Non -100 labels: {(item['labels'] != -100).sum().item()}")

# %% [markdown]
# ## 6. å­¦ç¿’

# %%
import os
import yaml

# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
os.makedirs(OUTPUT_DIR, exist_ok=True)
os.makedirs(EXP_DIR, exist_ok=True)
os.makedirs(DRIVE_EXP_DIR, exist_ok=True)

# è¨­å®šã‚’YAMLã§ä¿å­˜
config_with_metadata = {
    **CONFIG,
    "timestamp": datetime.now().isoformat(),
    "data_source": f"{HF_DATASET_REPO}/data/{DATASET_VERSION}.jsonl",
    "gpu_name": torch.cuda.get_device_name(0) if torch.cuda.is_available() else "CPU",
    "total_samples": len(samples),
    "train_samples": len(train_samples),
    "val_samples": len(val_samples),
    "test_samples": len(test_samples),
    "unique_emojis": len(emoji_counts),
}
with open(f"{EXP_DIR}/config.yaml", "w", encoding="utf-8") as f:
    yaml.dump(config_with_metadata, f, allow_unicode=True, default_flow_style=False)
print(f"Config saved to {EXP_DIR}/config.yaml")

# å­¦ç¿’ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹Callbackï¼ˆsrc/models/t5_trainer.pyã‹ã‚‰ä½¿ç”¨ï¼‰
logging_callback = ExperimentLoggingCallback(f"{EXP_DIR}/train_log.csv")

# TrainConfigã‚’æ§‹ç¯‰
train_config = TrainConfig(
    model_name=CONFIG["model_name"],
    output_dir=OUTPUT_DIR,
    num_train_epochs=CONFIG["num_epochs"],
    per_device_train_batch_size=CONFIG["batch_size"],
    per_device_eval_batch_size=CONFIG["batch_size"],
    learning_rate=CONFIG["learning_rate"],
    weight_decay=CONFIG["weight_decay"],
    warmup_steps=CONFIG["warmup_steps"],
    logging_steps=CONFIG["logging_steps"],
    fp16=CONFIG["fp16"],
    label_smoothing_factor=CONFIG["label_smoothing"],
    early_stopping_patience=CONFIG["early_stopping_patience"],
    save_total_limit=3,
)

# Traineræ§‹ç¯‰ï¼ˆFocal Lossã®æœ‰ç„¡ã§åˆ‡ã‚Šæ›¿ãˆï¼‰
if CONFIG["use_focal_loss"]:
    print(f"Using FocalLossTrainer (gamma={CONFIG['focal_gamma']})")
    trainer = build_focal_loss_trainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        cfg=train_config,
        gamma=CONFIG["focal_gamma"],
    )
else:
    print("Using standard Trainer")
    trainer = build_trainer(
        model=model,
        tokenizer=tokenizer,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        cfg=train_config,
    )
# ã‚«ã‚¹ã‚¿ãƒ Callbackã‚’è¿½åŠ 
trainer.add_callback(logging_callback)

# GPUç§»å‹•
if torch.cuda.is_available():
    model.to("cuda")

print("Starting training...")

# %%
# å­¦ç¿’å®Ÿè¡Œ
trainer.train()

# %%
# ãƒ¢ãƒ‡ãƒ«ä¿å­˜
trainer.save_model(OUTPUT_DIR)
tokenizer.save_pretrained(OUTPUT_DIR)
print(f"Model saved to {OUTPUT_DIR}")

# å­¦ç¿’çµæœã‚’å–å¾—
train_result = trainer.state
best_epoch = train_result.best_metric if hasattr(train_result, 'best_metric') else None
print(f"Best model checkpoint: {train_result.best_model_checkpoint}")

# è©•ä¾¡çµæœä¿å­˜
eval_result = trainer.evaluate()
print(f"\nEval results: {eval_result}")

# %% [markdown]
# ## 7. æ¨è«–ãƒ†ã‚¹ãƒˆ

# %%
# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼ˆæš—è¨˜ç¢ºèªï¼‰
print("=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆï¼ˆSamplingï¼‰ ===")
for sample in train_samples[:5]:
    text = sample["sns_text"]
    expected = sample["emoji_string"]
    result = generate_emoji(model, tokenizer, text, use_sampling=True)
    match = "OK" if result.strip() == expected.strip() else "NG"
    print(f"[{match}] å…¥åŠ›: {text[:40]}...")
    print(f"     æœŸå¾…: {expected}")
    print(f"     å‡ºåŠ›: {result}")
    print()

# %%
# Beam search ã¨ã®æ¯”è¼ƒ
print("=== Beam Search vs Sampling æ¯”è¼ƒ ===")
for sample in train_samples[:3]:
    text = sample["sns_text"]
    expected = sample["emoji_string"]
    result_beam = generate_emoji(model, tokenizer, text, use_sampling=False)
    result_sample = generate_emoji(model, tokenizer, text, use_sampling=True)
    print(f"å…¥åŠ›: {text[:40]}...")
    print(f"  æœŸå¾…: {expected}")
    print(f"  Beam: {result_beam}")
    print(f"  Sample: {result_sample}")
    print()

# %%
# æ–°è¦ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ†ã‚¹ãƒˆ
print("=== æ–°è¦ãƒ†ã‚­ã‚¹ãƒˆã§ã®ãƒ†ã‚¹ãƒˆ ===")
test_texts = [
    "ä»Šæ—¥ã¯æ¥½ã—ã‹ã£ãŸ",
    "æ˜æ—¥ã¯é›¨ã‚‰ã—ã„",
    "ãŠãªã‹ã™ã„ãŸ",
    "è©¦é¨“ã«åˆæ ¼ã—ãŸ",
    "æ¨ã—ãŒå°Šã„",
    "ã‚ã£ã¡ã‚ƒçœ ã„",
]

for text in test_texts:
    result = generate_emoji(model, tokenizer, text, use_sampling=True)
    print(f"å…¥åŠ›: {text}")
    print(f"å‡ºåŠ›: {result}")
    print()

# %% [markdown]
# ## 8. è©•ä¾¡æŒ‡æ¨™

# %%
# ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§è©•ä¾¡ï¼ˆå…¨ä»¶ï¼‰
print("=== ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡ ===")
eval_results = evaluate_model(model, tokenizer, test_samples)
print(f"Average Jaccard: {eval_results.avg_jaccard:.4f}")
print(f"Exact Match Rate: {eval_results.exact_match_rate:.4f}")
print(f"Micro F1: {eval_results.micro_f1:.4f}")
print(f"Avg Precision: {eval_results.avg_precision:.4f}")
print(f"Avg Recall: {eval_results.avg_recall:.4f}")
print(f"Avg F1: {eval_results.avg_f1:.4f}")
print(f"Samples evaluated: {eval_results.num_samples}")

# å¤šæ§˜æ€§æŒ‡æ¨™ï¼ˆTop-5çµµæ–‡å­—ä»¥å¤–ã®å‡ºåŠ›å‰²åˆï¼‰
predictions = [d["pred"] for d in eval_results.details]
diversity = diversity_ratio(predictions, TOP_5_EMOJIS)
print(f"\n=== å¤šæ§˜æ€§æŒ‡æ¨™ ===")
print(f"Non-Top5 Ratio: {diversity['non_top_n_ratio']:.4f}")
print(f"Unique Emojis in Output: {diversity['unique_emojis']}")
print(f"Top5 Count: {diversity['top_n_count']}, Non-Top5 Count: {diversity['non_top_n_count']}")

# å‡ºåŠ›çµµæ–‡å­—ã®åˆ†å¸ƒï¼ˆTop 10ï¼‰
pred_dist = emoji_distribution(predictions)
print(f"\n=== å‡ºåŠ›çµµæ–‡å­—ã®åˆ†å¸ƒï¼ˆTop 10ï¼‰ ===")
for i, (emoji, count) in enumerate(list(pred_dist.items())[:10]):
    print(f"  {emoji}: {count}")

# %%
# çµæœä¿å­˜
import json
import shutil

eval_metrics = {
    "avg_jaccard": eval_results.avg_jaccard,
    "exact_match_rate": eval_results.exact_match_rate,
    "micro_f1": eval_results.micro_f1,
    "avg_precision": eval_results.avg_precision,
    "avg_recall": eval_results.avg_recall,
    "avg_f1": eval_results.avg_f1,
    "num_samples": eval_results.num_samples,
    # å¤šæ§˜æ€§æŒ‡æ¨™
    "diversity_non_top5_ratio": diversity["non_top_n_ratio"],
    "diversity_unique_emojis": diversity["unique_emojis"],
    "diversity_top5_count": diversity["top_n_count"],
    "diversity_non_top5_count": diversity["non_top_n_count"],
}

with open(f"{EXP_DIR}/eval_metrics.json", "w", encoding="utf-8") as f:
    json.dump(eval_metrics, f, ensure_ascii=False, indent=2)
print(f"Metrics saved to {EXP_DIR}/eval_metrics.json")

# äºˆæ¸¬ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¿å­˜ï¼ˆæœ€åˆã®20ä»¶ï¼‰
with open(f"{EXP_DIR}/predictions_sample.jsonl", "w", encoding="utf-8") as f:
    for detail in eval_results.details[:20]:
        f.write(json.dumps(detail, ensure_ascii=False) + "\n")
print(f"Prediction samples saved to {EXP_DIR}/predictions_sample.jsonl")

# %% [markdown]
# ## 9. å®Ÿé¨“ã‚µãƒãƒªãƒ¼ç”Ÿæˆ

# %%
# ã‚µãƒãƒªãƒ¼Markdownç”Ÿæˆ
summary_md = f"""# Experiment: {EXPERIMENT_NAME}

## Overview
- **Dataset**: {DATASET_VERSION} ({len(samples)} samples)
- **Experiment Type**: {EXPERIMENT_TYPE}
- **Date**: {EXPERIMENT_DATE}
- **GPU**: {config_with_metadata.get('gpu_name', 'Unknown')}

## Configuration
| Parameter | Value |
|-----------|-------|
| Model | {CONFIG['model_name']} |
| Epochs | {CONFIG['num_epochs']} |
| Batch Size | {CONFIG['batch_size']} |
| Learning Rate | {CONFIG['learning_rate']} |
| Label Smoothing | {CONFIG['label_smoothing']} |
| Early Stopping | {CONFIG['early_stopping_patience']} epochs |
| FP16 | {CONFIG['fp16']} |

## Data Split
- Train: {len(train_samples)}
- Validation: {len(val_samples)}
- Test: {len(test_samples)}
- Unique Emojis: {len(emoji_counts)}

## Results
| Metric | Value |
|--------|-------|
| Average Jaccard | {eval_results.avg_jaccard:.4f} |
| Exact Match Rate | {eval_results.exact_match_rate:.4f} |
| Micro F1 | {eval_results.micro_f1:.4f} |
| Avg Precision | {eval_results.avg_precision:.4f} |
| Avg Recall | {eval_results.avg_recall:.4f} |
| Avg F1 | {eval_results.avg_f1:.4f} |

## Diversity Metrics
| Metric | Value |
|--------|-------|
| Non-Top5 Ratio | {diversity['non_top_n_ratio']:.4f} |
| Unique Emojis in Output | {diversity['unique_emojis']} |
| Top5 Count | {diversity['top_n_count']} |
| Non-Top5 Count | {diversity['non_top_n_count']} |

## Training Info
- Best Checkpoint: {train_result.best_model_checkpoint}
- Final Eval Loss: {eval_result.get('eval_loss', 'N/A')}

## Notes
<!-- å®Ÿé¨“ã«é–¢ã™ã‚‹ãƒ¡ãƒ¢ã‚’ã“ã“ã«è¨˜è¼‰ -->

"""

with open(f"{EXP_DIR}/summary.md", "w", encoding="utf-8") as f:
    f.write(summary_md)
print(f"Summary saved to {EXP_DIR}/summary.md")

# %%
# Google Driveã«ã‚³ãƒ”ãƒ¼
shutil.copytree(EXP_DIR, DRIVE_EXP_DIR, dirs_exist_ok=True)
print(f"\nExperiment files copied to Google Drive: {DRIVE_EXP_DIR}")
print("\nFiles saved:")
for fname in os.listdir(EXP_DIR):
    print(f"  - {fname}")

# %% [markdown]
# ## 10. GitHubã«å®Ÿé¨“ãƒ­ã‚°ã‚’ã‚³ãƒŸãƒƒãƒˆ
#
# Colab Secretsã« `GITHUB_TOKEN` ã‚’è¨­å®šã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã€‚
# GitHub â†’ Settings â†’ Developer settings â†’ Personal access tokens â†’ Fine-grained tokens
# - Repository access: AtefAndrus/Jmoji ã®ã¿
# - Permissions: Contents (Read and write)

# %%
from google.colab import userdata

try:
    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')
    REPO_URL = f"https://{GITHUB_TOKEN}@github.com/AtefAndrus/Jmoji.git"

    # gitè¨­å®š
    !git config user.name "AtefAndrus"
    !git config user.email "77284388+AtefAndrus@users.noreply.github.com"

    # å®Ÿé¨“ãƒ­ã‚°ã‚’ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥
    !git add outputs/experiments/{EXPERIMENT_NAME}/
    !git commit -m "[experiment] {EXPERIMENT_NAME}"
    !git push {REPO_URL} main

    print(f"\nExperiment {EXPERIMENT_NAME} pushed to GitHub")
except userdata.SecretNotFoundError:
    print("GITHUB_TOKEN not found in Colab Secrets. Skipping auto-commit.")
    print("To enable auto-commit, add GITHUB_TOKEN to Colab Secrets.")

# %% [markdown]
# ## 11. Hugging Face Hubã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
#
# Colab Secretsã« `HF_TOKEN` ã‚’è¨­å®šã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã€‚
# https://huggingface.co/settings/tokens â†’ Create new token (Writeæ¨©é™)

# %%
from huggingface_hub import login, HfApi

try:
    HF_TOKEN = userdata.get('HF_TOKEN')
    login(token=HF_TOKEN)

    # ãƒªãƒã‚¸ãƒˆãƒªå: jmoji-t5-{experiment_name}
    repo_name = f"jmoji-t5-{EXPERIMENT_NAME}"
    repo_id = f"AtefAndrus/{repo_name}"

    print(f"Uploading model to Hugging Face Hub: {repo_id}")

    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆprivateãƒªãƒã‚¸ãƒˆãƒªï¼‰
    model.push_to_hub(repo_id, private=True)
    tokenizer.push_to_hub(repo_id, private=True)

    # å®Ÿé¨“è¨­å®šã‚‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
    api = HfApi()
    api.upload_file(
        path_or_fileobj=f"{EXP_DIR}/config.yaml",
        path_in_repo="experiment_config.yaml",
        repo_id=repo_id,
        repo_type="model",
    )
    api.upload_file(
        path_or_fileobj=f"{EXP_DIR}/eval_metrics.json",
        path_in_repo="eval_metrics.json",
        repo_id=repo_id,
        repo_type="model",
    )

    print(f"\nModel uploaded to: https://huggingface.co/{repo_id}")

except userdata.SecretNotFoundError:
    print("HF_TOKEN not found in Colab Secrets. Skipping HF Hub upload.")
    print("To enable upload, add HF_TOKEN (Write permission) to Colab Secrets.")
except Exception as e:
    print(f"Failed to upload to HF Hub: {e}")
