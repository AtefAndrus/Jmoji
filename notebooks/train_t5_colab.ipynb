{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ddb89d7",
   "metadata": {},
   "source": [
    "# Jmoji T5 Training on Google Colab\n",
    "\n",
    "æ—¥æœ¬èªãƒ†ã‚­ã‚¹ãƒˆâ†’çµµæ–‡å­—ç¿»è¨³ãƒ¢ãƒ‡ãƒ«ã®å­¦ç¿’ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64cc352",
   "metadata": {},
   "source": [
    "## 1. ç’°å¢ƒã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3454463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveã‚’ãƒã‚¦ãƒ³ãƒˆ\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89ee0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒªãƒã‚¸ãƒˆãƒªã‚¯ãƒ­ãƒ¼ãƒ³\n",
    "!git clone https://github.com/AtefAndrus/Jmoji.git\n",
    "%cd /content/Jmoji"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a680aca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ä¾å­˜é–¢ä¿‚ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆpyproject.tomlã‹ã‚‰è‡ªå‹•è§£æ±ºï¼‰\n",
    "!pip install -q ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4c1a80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUç¢ºèª\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Device: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7d6da9",
   "metadata": {},
   "source": [
    "## 2. è¨­å®š\n",
    "\n",
    "å®Ÿé¨“ã‚¿ã‚¤ãƒ—ã‚’å¤‰æ›´ã™ã‚‹ã“ã¨ã§ã€ç•°ãªã‚‹è¨­å®šã§å­¦ç¿’ã‚’å®Ÿè¡Œã§ãã‚‹ã€‚\n",
    "\n",
    "| å®Ÿé¨“ã‚¿ã‚¤ãƒ— | èª¬æ˜ |\n",
    "|-----------|------|\n",
    "| baseline | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ï¼ˆlr=3e-4ï¼‰ |\n",
    "| lr1e-4 | å­¦ç¿’ç‡èª¿æ•´ï¼ˆlr=1e-4ï¼‰ |\n",
    "| top100 | Top-100çµµæ–‡å­—åˆ¶é™ |\n",
    "| lr1e-4_top100 | lr=1e-4 + Top-100åˆ¶é™ |\n",
    "| focal | Focal Lossï¼ˆÎ³=2.0ï¼‰ |\n",
    "| focal_top100 | Focal Loss + Top-100åˆ¶é™ |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59aeb57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "# =============================================================================\n",
    "# å®Ÿé¨“è¨­å®šï¼ˆã“ã“ã‚’å¤‰æ›´ã—ã¦å®Ÿé¨“ã‚’åˆ‡ã‚Šæ›¿ãˆã‚‹ï¼‰\n",
    "# =============================================================================\n",
    "DATASET_VERSION = \"v4\"\n",
    "EXPERIMENT_TYPE = \"focal_top100\"  # baseline, lr1e-4, top100, lr1e-4_top100, focal, focal_top100\n",
    "\n",
    "# =============================================================================\n",
    "# å®Ÿé¨“ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè¨­å®šã®è‡ªå‹•èª¿æ•´\n",
    "# =============================================================================\n",
    "EXPERIMENT_DATE = datetime.now().strftime(\"%Y%m%d\")\n",
    "EXPERIMENT_NAME = f\"{DATASET_VERSION}_{EXPERIMENT_TYPE}_{EXPERIMENT_DATE}\"\n",
    "\n",
    "# ãƒ‘ã‚¹è¨­å®š\n",
    "HF_DATASET_REPO = \"AtefAndrus/jmoji-dataset\"\n",
    "OUTPUT_DIR = \"/content/Jmoji/outputs/models\"\n",
    "EXP_DIR = f\"/content/Jmoji/outputs/experiments/{EXPERIMENT_NAME}\"\n",
    "DRIVE_EXP_DIR = f\"/content/drive/MyDrive/school/ai_application/experiments/{EXPERIMENT_NAME}\"\n",
    "\n",
    "# ãƒ™ãƒ¼ã‚¹è¨­å®š\n",
    "CONFIG = {\n",
    "    \"experiment_name\": EXPERIMENT_NAME,\n",
    "    \"dataset_version\": DATASET_VERSION,\n",
    "    \"experiment_type\": EXPERIMENT_TYPE,\n",
    "    \"model_name\": \"sonoisa/t5-base-japanese\",\n",
    "    \"num_epochs\": 50,\n",
    "    \"batch_size\": 16,\n",
    "    \"learning_rate\": 3e-4,  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ\n",
    "    \"weight_decay\": 0.01,\n",
    "    \"warmup_steps\": 150,\n",
    "    \"max_input_length\": 128,\n",
    "    \"max_output_length\": 32,\n",
    "    \"train_ratio\": 0.8,\n",
    "    \"val_ratio\": 0.1,\n",
    "    \"test_ratio\": 0.1,\n",
    "    \"fp16\": False,\n",
    "    \"logging_steps\": 50,\n",
    "    \"label_smoothing\": 0.1,\n",
    "    \"early_stopping_patience\": 5,\n",
    "    # å®Ÿé¨“å›ºæœ‰ã®è¨­å®š\n",
    "    \"use_focal_loss\": False,\n",
    "    \"focal_gamma\": 2.0,\n",
    "    \"use_top100_filter\": False,\n",
    "}\n",
    "\n",
    "# å®Ÿé¨“ã‚¿ã‚¤ãƒ—ã«å¿œã˜ãŸè¨­å®šã®ä¸Šæ›¸ã\n",
    "if \"lr1e-4\" in EXPERIMENT_TYPE:\n",
    "    CONFIG[\"learning_rate\"] = 1e-4\n",
    "    print(\"Setting: learning_rate = 1e-4\")\n",
    "\n",
    "if \"top100\" in EXPERIMENT_TYPE:\n",
    "    CONFIG[\"use_top100_filter\"] = True\n",
    "    print(\"Setting: Top-100 emoji filter enabled\")\n",
    "\n",
    "if \"focal\" in EXPERIMENT_TYPE:\n",
    "    CONFIG[\"use_focal_loss\"] = True\n",
    "    CONFIG[\"label_smoothing\"] = 0.0  # Focal Lossã¨ä½µç”¨ã—ãªã„\n",
    "    print(\"Setting: Focal Loss enabled (gamma=2.0)\")\n",
    "\n",
    "print(f\"\\nExperiment: {EXPERIMENT_NAME}\")\n",
    "print(f\"Dataset: {HF_DATASET_REPO} ({DATASET_VERSION})\")\n",
    "print(f\"Experiment dir: {EXP_DIR}\")\n",
    "print(\"\\nConfig:\")\n",
    "for k, v in CONFIG.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "650e4ba6",
   "metadata": {},
   "source": [
    "## 3. ãƒ‡ãƒ¼ã‚¿æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acb0be78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/content/Jmoji\")\n",
    "\n",
    "# HuggingFace Hubã«ãƒ­ã‚°ã‚¤ãƒ³ï¼ˆprivateãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚¢ã‚¯ã‚»ã‚¹ç”¨ï¼‰\n",
    "from huggingface_hub import login\n",
    "from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "    login(token=HF_TOKEN)\n",
    "    print(\"Logged in to HuggingFace Hub\")\n",
    "except userdata.SecretNotFoundError:\n",
    "    print(\"HF_TOKEN not found. Proceeding without login (public datasets only).\")\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "from src.models.t5_trainer import (\n",
    "    EmojiDataset,\n",
    "    TrainConfig,\n",
    "    setup_model_with_emoji_tokens,\n",
    "    build_trainer,\n",
    "    build_focal_loss_trainer,\n",
    "    ExperimentLoggingCallback,\n",
    "    split_dataset,\n",
    "    generate_emoji,\n",
    "    evaluate_model,\n",
    ")\n",
    "from src.evaluation.metrics import (\n",
    "    diversity_ratio,\n",
    "    emoji_distribution,\n",
    "    compute_emoji_stats,\n",
    ")\n",
    "from src.data.emoji_utils import filter_samples_by_top_emojis\n",
    "\n",
    "# HuggingFace Hubã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã‚’ãƒ­ãƒ¼ãƒ‰\n",
    "hf_dataset = load_dataset(\n",
    "    HF_DATASET_REPO,\n",
    "    data_files=f\"data/{DATASET_VERSION}.jsonl\",\n",
    "    split=\"train\",\n",
    ")\n",
    "samples = list(hf_dataset)\n",
    "print(f\"Total samples: {len(samples)}\")\n",
    "\n",
    "# åˆ†å‰²\n",
    "train_samples, val_samples, test_samples = split_dataset(\n",
    "    samples,\n",
    "    CONFIG[\"train_ratio\"],\n",
    "    CONFIG[\"val_ratio\"]\n",
    ")\n",
    "print(f\"Train: {len(train_samples)}, Val: {len(val_samples)}, Test: {len(test_samples)}\")\n",
    "\n",
    "# ã‚µãƒ³ãƒ—ãƒ«ç¢ºèª\n",
    "print(\"\\nSample data:\")\n",
    "for i, s in enumerate(train_samples[:3]):\n",
    "    print(f\"  [{i}] {s['sns_text'][:50]}... -> {s['emoji_string']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfd0cbfd",
   "metadata": {},
   "source": [
    "## 3.5 çµµæ–‡å­—åˆ†å¸ƒã®ç¢ºèª"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003470c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµµæ–‡å­—çµ±è¨ˆã‚’è¨ˆç®—ï¼ˆsrc/evaluation/metrics.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰\n",
    "emoji_counts, total_emoji_count, unique_emoji_count = compute_emoji_stats(samples)\n",
    "\n",
    "print(f\"Total emoji occurrences: {total_emoji_count}\")\n",
    "print(f\"Unique emojis: {unique_emoji_count}\")\n",
    "print(\"\\nTop 20 emojis:\")\n",
    "for emoji, count in emoji_counts.most_common(20):\n",
    "    pct = count / total_emoji_count * 100\n",
    "    print(f\"  {emoji}: {count} ({pct:.1f}%)\")\n",
    "\n",
    "# æœ€é »å‡ºçµµæ–‡å­—ã®å‰²åˆã‚’è­¦å‘Š\n",
    "top_emoji, top_count = emoji_counts.most_common(1)[0]\n",
    "top_pct = top_count / total_emoji_count * 100\n",
    "if top_pct > 15:\n",
    "    print(f\"\\nWarning: '{top_emoji}' is {top_pct:.1f}% of all emojis. This may cause mode collapse.\")\n",
    "\n",
    "# Top-5çµµæ–‡å­—ã‚’ä¿å­˜ï¼ˆè©•ä¾¡æ™‚ã®å¤šæ§˜æ€§æŒ‡æ¨™ã§ä½¿ç”¨ï¼‰\n",
    "TOP_5_EMOJIS = set(e for e, _ in emoji_counts.most_common(5))\n",
    "print(f\"\\nTop 5 emojis (for diversity metric): {TOP_5_EMOJIS}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dba5f7",
   "metadata": {},
   "source": [
    "## 3.6 Top-100çµµæ–‡å­—ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰\n",
    "\n",
    "`use_top100_filter=True` ã®å ´åˆã€Top-100çµµæ–‡å­—ã®ã¿ã‚’å«ã‚€ã‚µãƒ³ãƒ—ãƒ«ã«åˆ¶é™ã™ã‚‹ã€‚"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb594ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG[\"use_top100_filter\"]:\n",
    "    # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆsrc/data/emoji_utils.pyã®é–¢æ•°ã‚’ä½¿ç”¨ï¼‰\n",
    "    original_count = len(samples)\n",
    "    samples, emoji_counts, top_100_emojis = filter_samples_by_top_emojis(\n",
    "        samples, top_n=100\n",
    "    )\n",
    "    print(f\"Top-100 emojis: {len(top_100_emojis)}\")\n",
    "    print(f\"Filtered samples: {len(samples)} / {original_count} ({len(samples)/original_count*100:.1f}%)\")\n",
    "    print(f\"Unique emojis after filter: {len(emoji_counts)}\")\n",
    "\n",
    "    # åˆ†å‰²ã‚’å†å®Ÿè¡Œ\n",
    "    train_samples, val_samples, test_samples = split_dataset(\n",
    "        samples,\n",
    "        CONFIG[\"train_ratio\"],\n",
    "        CONFIG[\"val_ratio\"]\n",
    "    )\n",
    "    print(f\"Train: {len(train_samples)}, Val: {len(val_samples)}, Test: {len(test_samples)}\")\n",
    "else:\n",
    "    print(\"Top-100 filter: DISABLED\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf745b28",
   "metadata": {},
   "source": [
    "## 4. ãƒ¢ãƒ‡ãƒ«ãƒ»ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶æº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801cdfc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer, model = setup_model_with_emoji_tokens(CONFIG[\"model_name\"])\n",
    "print(f\"Vocab size: {len(tokenizer)}\")\n",
    "\n",
    "# çµµæ–‡å­—ãƒˆãƒ¼ã‚¯ãƒ³åŒ–ç¢ºèª\n",
    "test_emoji = \"ğŸ˜Š ğŸ‰\"\n",
    "ids = tokenizer.encode(test_emoji, add_special_tokens=False)\n",
    "decoded = tokenizer.decode(ids)\n",
    "print(f\"Emoji tokenization test: '{test_emoji}' -> {ids} -> '{decoded}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34d207af",
   "metadata": {},
   "source": [
    "## 5. Datasetæº–å‚™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667b8125",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Datasetä½œæˆ\n",
    "train_dataset = EmojiDataset(\n",
    "    train_samples, tokenizer,\n",
    "    CONFIG[\"max_input_length\"],\n",
    "    CONFIG[\"max_output_length\"]\n",
    ")\n",
    "val_dataset = EmojiDataset(\n",
    "    val_samples, tokenizer,\n",
    "    CONFIG[\"max_input_length\"],\n",
    "    CONFIG[\"max_output_length\"]\n",
    ")\n",
    "test_dataset = EmojiDataset(\n",
    "    test_samples, tokenizer,\n",
    "    CONFIG[\"max_input_length\"],\n",
    "    CONFIG[\"max_output_length\"]\n",
    ")\n",
    "\n",
    "print(f\"Train dataset: {len(train_dataset)}\")\n",
    "print(f\"Val dataset: {len(val_dataset)}\")\n",
    "print(f\"Test dataset: {len(test_dataset)}\")\n",
    "\n",
    "# ãƒ‡ãƒ¼ã‚¿ç¢ºèª\n",
    "item = train_dataset[0]\n",
    "print(f\"\\nSample item shapes:\")\n",
    "print(f\"  input_ids: {item['input_ids'].shape}\")\n",
    "print(f\"  attention_mask: {item['attention_mask'].shape}\")\n",
    "print(f\"  labels: {item['labels'].shape}\")\n",
    "print(f\"  Non -100 labels: {(item['labels'] != -100).sum().item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2467f5",
   "metadata": {},
   "source": [
    "## 6. å­¦ç¿’"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4fe27de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import yaml\n",
    "\n",
    "# å‡ºåŠ›ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "os.makedirs(EXP_DIR, exist_ok=True)\n",
    "os.makedirs(DRIVE_EXP_DIR, exist_ok=True)\n",
    "\n",
    "# è¨­å®šã‚’YAMLã§ä¿å­˜\n",
    "config_with_metadata = {\n",
    "    **CONFIG,\n",
    "    \"timestamp\": datetime.now().isoformat(),\n",
    "    \"data_source\": f\"{HF_DATASET_REPO}/data/{DATASET_VERSION}.jsonl\",\n",
    "    \"gpu_name\": torch.cuda.get_device_name(0) if torch.cuda.is_available() else \"CPU\",\n",
    "    \"total_samples\": len(samples),\n",
    "    \"train_samples\": len(train_samples),\n",
    "    \"val_samples\": len(val_samples),\n",
    "    \"test_samples\": len(test_samples),\n",
    "    \"unique_emojis\": len(emoji_counts),\n",
    "}\n",
    "with open(f\"{EXP_DIR}/config.yaml\", \"w\", encoding=\"utf-8\") as f:\n",
    "    yaml.dump(config_with_metadata, f, allow_unicode=True, default_flow_style=False)\n",
    "print(f\"Config saved to {EXP_DIR}/config.yaml\")\n",
    "\n",
    "# å­¦ç¿’ãƒ­ã‚°ã‚’è¨˜éŒ²ã™ã‚‹Callbackï¼ˆsrc/models/t5_trainer.pyã‹ã‚‰ä½¿ç”¨ï¼‰\n",
    "logging_callback = ExperimentLoggingCallback(f\"{EXP_DIR}/train_log.csv\")\n",
    "\n",
    "# TrainConfigã‚’æ§‹ç¯‰\n",
    "train_config = TrainConfig(\n",
    "    model_name=CONFIG[\"model_name\"],\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=CONFIG[\"num_epochs\"],\n",
    "    per_device_train_batch_size=CONFIG[\"batch_size\"],\n",
    "    per_device_eval_batch_size=CONFIG[\"batch_size\"],\n",
    "    learning_rate=CONFIG[\"learning_rate\"],\n",
    "    weight_decay=CONFIG[\"weight_decay\"],\n",
    "    warmup_steps=CONFIG[\"warmup_steps\"],\n",
    "    logging_steps=CONFIG[\"logging_steps\"],\n",
    "    fp16=CONFIG[\"fp16\"],\n",
    "    label_smoothing_factor=CONFIG[\"label_smoothing\"],\n",
    "    early_stopping_patience=CONFIG[\"early_stopping_patience\"],\n",
    "    save_total_limit=3,\n",
    ")\n",
    "\n",
    "# Traineræ§‹ç¯‰ï¼ˆFocal Lossã®æœ‰ç„¡ã§åˆ‡ã‚Šæ›¿ãˆï¼‰\n",
    "if CONFIG[\"use_focal_loss\"]:\n",
    "    print(f\"Using FocalLossTrainer (gamma={CONFIG['focal_gamma']})\")\n",
    "    trainer = build_focal_loss_trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        cfg=train_config,\n",
    "        gamma=CONFIG[\"focal_gamma\"],\n",
    "    )\n",
    "else:\n",
    "    print(\"Using standard Trainer\")\n",
    "    trainer = build_trainer(\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        cfg=train_config,\n",
    "    )\n",
    "# ã‚«ã‚¹ã‚¿ãƒ Callbackã‚’è¿½åŠ \n",
    "trainer.add_callback(logging_callback)\n",
    "\n",
    "# GPUç§»å‹•\n",
    "if torch.cuda.is_available():\n",
    "    model.to(\"cuda\")\n",
    "\n",
    "print(\"Starting training...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc780e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’å®Ÿè¡Œ\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c942bce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ¢ãƒ‡ãƒ«ä¿å­˜\n",
    "trainer.save_model(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"Model saved to {OUTPUT_DIR}\")\n",
    "\n",
    "# å­¦ç¿’çµæœã‚’å–å¾—\n",
    "train_result = trainer.state\n",
    "best_epoch = train_result.best_metric if hasattr(train_result, 'best_metric') else None\n",
    "print(f\"Best model checkpoint: {train_result.best_model_checkpoint}\")\n",
    "\n",
    "# è©•ä¾¡çµæœä¿å­˜\n",
    "eval_result = trainer.evaluate()\n",
    "print(f\"\\nEval results: {eval_result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c9fdf3",
   "metadata": {},
   "source": [
    "## 7. æ¨è«–ãƒ†ã‚¹ãƒˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2791771f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ãƒ†ã‚¹ãƒˆï¼ˆæš—è¨˜ç¢ºèªï¼‰\n",
    "print(\"=== å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã§ã®ãƒ†ã‚¹ãƒˆï¼ˆSamplingï¼‰ ===\")\n",
    "for sample in train_samples[:5]:\n",
    "    text = sample[\"sns_text\"]\n",
    "    expected = sample[\"emoji_string\"]\n",
    "    result = generate_emoji(model, tokenizer, text, use_sampling=True)\n",
    "    match = \"OK\" if result.strip() == expected.strip() else \"NG\"\n",
    "    print(f\"[{match}] å…¥åŠ›: {text[:40]}...\")\n",
    "    print(f\"     æœŸå¾…: {expected}\")\n",
    "    print(f\"     å‡ºåŠ›: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "719f22df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Beam search ã¨ã®æ¯”è¼ƒ\n",
    "print(\"=== Beam Search vs Sampling æ¯”è¼ƒ ===\")\n",
    "for sample in train_samples[:3]:\n",
    "    text = sample[\"sns_text\"]\n",
    "    expected = sample[\"emoji_string\"]\n",
    "    result_beam = generate_emoji(model, tokenizer, text, use_sampling=False)\n",
    "    result_sample = generate_emoji(model, tokenizer, text, use_sampling=True)\n",
    "    print(f\"å…¥åŠ›: {text[:40]}...\")\n",
    "    print(f\"  æœŸå¾…: {expected}\")\n",
    "    print(f\"  Beam: {result_beam}\")\n",
    "    print(f\"  Sample: {result_sample}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ffb272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# æ–°è¦ãƒ†ã‚­ã‚¹ãƒˆã§ãƒ†ã‚¹ãƒˆ\n",
    "print(\"=== æ–°è¦ãƒ†ã‚­ã‚¹ãƒˆã§ã®ãƒ†ã‚¹ãƒˆ ===\")\n",
    "test_texts = [\n",
    "    \"ä»Šæ—¥ã¯æ¥½ã—ã‹ã£ãŸ\",\n",
    "    \"æ˜æ—¥ã¯é›¨ã‚‰ã—ã„\",\n",
    "    \"ãŠãªã‹ã™ã„ãŸ\",\n",
    "    \"è©¦é¨“ã«åˆæ ¼ã—ãŸ\",\n",
    "    \"æ¨ã—ãŒå°Šã„\",\n",
    "    \"ã‚ã£ã¡ã‚ƒçœ ã„\",\n",
    "]\n",
    "\n",
    "for text in test_texts:\n",
    "    result = generate_emoji(model, tokenizer, text, use_sampling=True)\n",
    "    print(f\"å…¥åŠ›: {text}\")\n",
    "    print(f\"å‡ºåŠ›: {result}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa6da9c",
   "metadata": {},
   "source": [
    "## 8. è©•ä¾¡æŒ‡æ¨™"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56372c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆã§è©•ä¾¡ï¼ˆå…¨ä»¶ï¼‰\n",
    "print(\"=== ãƒ†ã‚¹ãƒˆã‚»ãƒƒãƒˆè©•ä¾¡ ===\")\n",
    "eval_results = evaluate_model(model, tokenizer, test_samples)\n",
    "print(f\"Average Jaccard: {eval_results.avg_jaccard:.4f}\")\n",
    "print(f\"Exact Match Rate: {eval_results.exact_match_rate:.4f}\")\n",
    "print(f\"Micro F1: {eval_results.micro_f1:.4f}\")\n",
    "print(f\"Avg Precision: {eval_results.avg_precision:.4f}\")\n",
    "print(f\"Avg Recall: {eval_results.avg_recall:.4f}\")\n",
    "print(f\"Avg F1: {eval_results.avg_f1:.4f}\")\n",
    "print(f\"Samples evaluated: {eval_results.num_samples}\")\n",
    "\n",
    "# å¤šæ§˜æ€§æŒ‡æ¨™ï¼ˆTop-5çµµæ–‡å­—ä»¥å¤–ã®å‡ºåŠ›å‰²åˆï¼‰\n",
    "predictions = [d[\"pred\"] for d in eval_results.details]\n",
    "diversity = diversity_ratio(predictions, TOP_5_EMOJIS)\n",
    "print(f\"\\n=== å¤šæ§˜æ€§æŒ‡æ¨™ ===\")\n",
    "print(f\"Non-Top5 Ratio: {diversity['non_top_n_ratio']:.4f}\")\n",
    "print(f\"Unique Emojis in Output: {diversity['unique_emojis']}\")\n",
    "print(f\"Top5 Count: {diversity['top_n_count']}, Non-Top5 Count: {diversity['non_top_n_count']}\")\n",
    "\n",
    "# å‡ºåŠ›çµµæ–‡å­—ã®åˆ†å¸ƒï¼ˆTop 10ï¼‰\n",
    "pred_dist = emoji_distribution(predictions)\n",
    "print(f\"\\n=== å‡ºåŠ›çµµæ–‡å­—ã®åˆ†å¸ƒï¼ˆTop 10ï¼‰ ===\")\n",
    "for i, (emoji, count) in enumerate(list(pred_dist.items())[:10]):\n",
    "    print(f\"  {emoji}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ef827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# çµæœä¿å­˜\n",
    "import json\n",
    "import shutil\n",
    "\n",
    "eval_metrics = {\n",
    "    \"avg_jaccard\": eval_results.avg_jaccard,\n",
    "    \"exact_match_rate\": eval_results.exact_match_rate,\n",
    "    \"micro_f1\": eval_results.micro_f1,\n",
    "    \"avg_precision\": eval_results.avg_precision,\n",
    "    \"avg_recall\": eval_results.avg_recall,\n",
    "    \"avg_f1\": eval_results.avg_f1,\n",
    "    \"num_samples\": eval_results.num_samples,\n",
    "    # å¤šæ§˜æ€§æŒ‡æ¨™\n",
    "    \"diversity_non_top5_ratio\": diversity[\"non_top_n_ratio\"],\n",
    "    \"diversity_unique_emojis\": diversity[\"unique_emojis\"],\n",
    "    \"diversity_top5_count\": diversity[\"top_n_count\"],\n",
    "    \"diversity_non_top5_count\": diversity[\"non_top_n_count\"],\n",
    "}\n",
    "\n",
    "with open(f\"{EXP_DIR}/eval_metrics.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(eval_metrics, f, ensure_ascii=False, indent=2)\n",
    "print(f\"Metrics saved to {EXP_DIR}/eval_metrics.json\")\n",
    "\n",
    "# äºˆæ¸¬ã‚µãƒ³ãƒ—ãƒ«ã‚’ä¿å­˜ï¼ˆæœ€åˆã®20ä»¶ï¼‰\n",
    "with open(f\"{EXP_DIR}/predictions_sample.jsonl\", \"w\", encoding=\"utf-8\") as f:\n",
    "    for detail in eval_results.details[:20]:\n",
    "        f.write(json.dumps(detail, ensure_ascii=False) + \"\\n\")\n",
    "print(f\"Prediction samples saved to {EXP_DIR}/predictions_sample.jsonl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46618eb0",
   "metadata": {},
   "source": [
    "## 9. å®Ÿé¨“ã‚µãƒãƒªãƒ¼ç”Ÿæˆ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6699692b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ã‚µãƒãƒªãƒ¼Markdownç”Ÿæˆ\n",
    "summary_md = f\"\"\"# Experiment: {EXPERIMENT_NAME}\n",
    "\n",
    "## Overview\n",
    "- **Dataset**: {DATASET_VERSION} ({len(samples)} samples)\n",
    "- **Experiment Type**: {EXPERIMENT_TYPE}\n",
    "- **Date**: {EXPERIMENT_DATE}\n",
    "- **GPU**: {config_with_metadata.get('gpu_name', 'Unknown')}\n",
    "\n",
    "## Configuration\n",
    "| Parameter | Value |\n",
    "|-----------|-------|\n",
    "| Model | {CONFIG['model_name']} |\n",
    "| Epochs | {CONFIG['num_epochs']} |\n",
    "| Batch Size | {CONFIG['batch_size']} |\n",
    "| Learning Rate | {CONFIG['learning_rate']} |\n",
    "| Label Smoothing | {CONFIG['label_smoothing']} |\n",
    "| Early Stopping | {CONFIG['early_stopping_patience']} epochs |\n",
    "| FP16 | {CONFIG['fp16']} |\n",
    "\n",
    "## Data Split\n",
    "- Train: {len(train_samples)}\n",
    "- Validation: {len(val_samples)}\n",
    "- Test: {len(test_samples)}\n",
    "- Unique Emojis: {len(emoji_counts)}\n",
    "\n",
    "## Results\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Average Jaccard | {eval_results.avg_jaccard:.4f} |\n",
    "| Exact Match Rate | {eval_results.exact_match_rate:.4f} |\n",
    "| Micro F1 | {eval_results.micro_f1:.4f} |\n",
    "| Avg Precision | {eval_results.avg_precision:.4f} |\n",
    "| Avg Recall | {eval_results.avg_recall:.4f} |\n",
    "| Avg F1 | {eval_results.avg_f1:.4f} |\n",
    "\n",
    "## Diversity Metrics\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| Non-Top5 Ratio | {diversity['non_top_n_ratio']:.4f} |\n",
    "| Unique Emojis in Output | {diversity['unique_emojis']} |\n",
    "| Top5 Count | {diversity['top_n_count']} |\n",
    "| Non-Top5 Count | {diversity['non_top_n_count']} |\n",
    "\n",
    "## Training Info\n",
    "- Best Checkpoint: {train_result.best_model_checkpoint}\n",
    "- Final Eval Loss: {eval_result.get('eval_loss', 'N/A')}\n",
    "\n",
    "## Notes\n",
    "<!-- å®Ÿé¨“ã«é–¢ã™ã‚‹ãƒ¡ãƒ¢ã‚’ã“ã“ã«è¨˜è¼‰ -->\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "with open(f\"{EXP_DIR}/summary.md\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(summary_md)\n",
    "print(f\"Summary saved to {EXP_DIR}/summary.md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60e2827f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Google Driveã«ã‚³ãƒ”ãƒ¼\n",
    "shutil.copytree(EXP_DIR, DRIVE_EXP_DIR, dirs_exist_ok=True)\n",
    "print(f\"\\nExperiment files copied to Google Drive: {DRIVE_EXP_DIR}\")\n",
    "print(\"\\nFiles saved:\")\n",
    "for fname in os.listdir(EXP_DIR):\n",
    "    print(f\"  - {fname}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb1fbc2",
   "metadata": {},
   "source": [
    "## 10. GitHubã«å®Ÿé¨“ãƒ­ã‚°ã‚’ã‚³ãƒŸãƒƒãƒˆ\n",
    "\n",
    "Colab Secretsã« `GITHUB_TOKEN` ã‚’è¨­å®šã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã€‚\n",
    "GitHub â†’ Settings â†’ Developer settings â†’ Personal access tokens â†’ Fine-grained tokens\n",
    "- Repository access: AtefAndrus/Jmoji ã®ã¿\n",
    "- Permissions: Contents (Read and write)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "badf02ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import userdata\n",
    "\n",
    "try:\n",
    "    GITHUB_TOKEN = userdata.get('GITHUB_TOKEN')\n",
    "    REPO_URL = f\"https://{GITHUB_TOKEN}@github.com/AtefAndrus/Jmoji.git\"\n",
    "\n",
    "    # gitè¨­å®š\n",
    "    !git config user.name \"AtefAndrus\"\n",
    "    !git config user.email \"77284388+AtefAndrus@users.noreply.github.com\"\n",
    "\n",
    "    # å®Ÿé¨“ãƒ­ã‚°ã‚’ã‚³ãƒŸãƒƒãƒˆãƒ»ãƒ—ãƒƒã‚·ãƒ¥\n",
    "    !git add outputs/experiments/{EXPERIMENT_NAME}/\n",
    "    !git commit -m \"[experiment] {EXPERIMENT_NAME}\"\n",
    "    !git push {REPO_URL} main\n",
    "\n",
    "    print(f\"\\nExperiment {EXPERIMENT_NAME} pushed to GitHub\")\n",
    "except userdata.SecretNotFoundError:\n",
    "    print(\"GITHUB_TOKEN not found in Colab Secrets. Skipping auto-commit.\")\n",
    "    print(\"To enable auto-commit, add GITHUB_TOKEN to Colab Secrets.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c12ced",
   "metadata": {},
   "source": [
    "## 11. Hugging Face Hubã«ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "\n",
    "Colab Secretsã« `HF_TOKEN` ã‚’è¨­å®šã—ã¦ãŠãå¿…è¦ãŒã‚ã‚‹ã€‚\n",
    "https://huggingface.co/settings/tokens â†’ Create new token (Writeæ¨©é™)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb028a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import login, HfApi\n",
    "\n",
    "try:\n",
    "    HF_TOKEN = userdata.get('HF_TOKEN')\n",
    "    login(token=HF_TOKEN)\n",
    "\n",
    "    # ãƒªãƒã‚¸ãƒˆãƒªå: jmoji-t5-{experiment_name}\n",
    "    repo_name = f\"jmoji-t5-{EXPERIMENT_NAME}\"\n",
    "    repo_id = f\"AtefAndrus/{repo_name}\"\n",
    "\n",
    "    print(f\"Uploading model to Hugging Face Hub: {repo_id}\")\n",
    "\n",
    "    # ãƒ¢ãƒ‡ãƒ«ã¨ãƒˆãƒ¼ã‚¯ãƒŠã‚¤ã‚¶ã‚’ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ï¼ˆprivateãƒªãƒã‚¸ãƒˆãƒªï¼‰\n",
    "    model.push_to_hub(repo_id, private=True)\n",
    "    tokenizer.push_to_hub(repo_id, private=True)\n",
    "\n",
    "    # å®Ÿé¨“è¨­å®šã‚‚ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰\n",
    "    api = HfApi()\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=f\"{EXP_DIR}/config.yaml\",\n",
    "        path_in_repo=\"experiment_config.yaml\",\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"model\",\n",
    "    )\n",
    "    api.upload_file(\n",
    "        path_or_fileobj=f\"{EXP_DIR}/eval_metrics.json\",\n",
    "        path_in_repo=\"eval_metrics.json\",\n",
    "        repo_id=repo_id,\n",
    "        repo_type=\"model\",\n",
    "    )\n",
    "\n",
    "    print(f\"\\nModel uploaded to: https://huggingface.co/{repo_id}\")\n",
    "\n",
    "except userdata.SecretNotFoundError:\n",
    "    print(\"HF_TOKEN not found in Colab Secrets. Skipping HF Hub upload.\")\n",
    "    print(\"To enable upload, add HF_TOKEN (Write permission) to Colab Secrets.\")\n",
    "except Exception as e:\n",
    "    print(f\"Failed to upload to HF Hub: {e}\")"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
