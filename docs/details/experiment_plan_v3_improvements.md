# å®Ÿé¨“è¨ˆç”»: v3ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã§ã®å­¦ç¿’æ”¹å–„

## æ¦‚è¦

æœ¬ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€v3ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆï¼ˆ5,000ä»¶ï¼‰ã§ã®å­¦ç¿’çµæœï¼ˆ[experiment_v3_5000samples.md](experiment_v3_5000samples.md)ï¼‰ã‚’å—ã‘ã¦ã€Soft Mode Collapseã‚’è§£æ¶ˆã™ã‚‹ãŸã‚ã®å®Ÿé¨“è¨ˆç”»ã‚’è¨˜è¿°ã™ã‚‹ã€‚

**ç›®æ¨™**: Top5çµµæ–‡å­—ã¸ã®åã‚Šã‚’è§£æ¶ˆã—ã€Jaccard > 0.10ã‚’é”æˆã™ã‚‹

---

## èƒŒæ™¯

### ç¾çŠ¶ã®å•é¡Œï¼ˆv3_baselineï¼‰

| æŒ‡æ¨™ | å€¤ | è©•ä¾¡ |
|------|-----|------|
| Average Jaccard | 0.0449 | éå¸¸ã«ä½ã„ |
| Exact Match Rate | 0.0000 | å®Œå…¨ä¸€è‡´ãªã— |
| Micro F1 | 0.0766 | ã»ã¼ãƒ©ãƒ³ãƒ€ãƒ  |

**Soft Mode Collapse**: å‡ºåŠ›ãŒTop5çµµæ–‡å­—ï¼ˆğŸµã€ğŸ“šã€ğŸ¤ã€ğŸ‰ã€ğŸ†ï¼‰ã«é›†ä¸­

### åŸå› ã®ä»®èª¬

1. **å­¦ç¿’ç‡ãŒé«˜ã™ãã‚‹**: é »å‡ºã‚¯ãƒ©ã‚¹ã«æ—©æœŸåæŸ
2. **çµµæ–‡å­—ç¨®é¡ãŒå¤šã™ãã‚‹**: 785ç¨®é¡ã«å¯¾ã—ã¦4,000ä»¶ã§ã¯ä¸è¶³ï¼ˆ1çµµæ–‡å­—ã‚ãŸã‚Šå¹³å‡5ä»¶ï¼‰
3. **ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼æå¤±ã®é™ç•Œ**: ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡ã«å¼±ã„

---

## å®Ÿé¨“è¨ˆç”»

### æ–¹é‡

- å¤‰æ•°ã‚’1ã¤ãšã¤å¤‰ãˆã¦åŠ¹æœã‚’æ¤œè¨¼ï¼ˆç§‘å­¦çš„ã‚¢ãƒ—ãƒ­ãƒ¼ãƒï¼‰
- v3_baseline ã‚’åŸºæº–ã¨ã—ã¦æ¯”è¼ƒ
- åŠ¹æœãŒç¢ºèªã§ããŸã‚‰çµ„ã¿åˆã‚ã›

### å®Ÿé¨“ä¸€è¦§

| # | å®Ÿé¨“å | å¤‰æ›´ç‚¹ | å®Ÿè£…é›£åº¦ | çŠ¶æ…‹ |
|---|--------|--------|---------|------|
| 0 | v3_baseline | - | - | å®Œäº† |
| 1 | v3_lr1e-4 | learning_rate: 3e-4â†’1e-4 | ä½ | æœªå®Ÿæ–½ |
| 2 | v3_top100 | çµµæ–‡å­—ã‚’Top-100ã«åˆ¶é™ | ä¸­ | æœªå®Ÿæ–½ |
| 3 | v3_lr1e-4_top100 | 1+2ã®çµ„ã¿åˆã‚ã› | ä½ | æœªå®Ÿæ–½ |
| 4 | v3_focal | Focal Loss (Î³=2) | é«˜ | æœªå®Ÿæ–½ |

---

## å„å®Ÿé¨“ã®è©³ç´°

### Exp1: å­¦ç¿’ç‡èª¿æ•´ (v3_lr1e-4)

**ä»®èª¬**: å­¦ç¿’ç‡ãŒé«˜ã™ãã¦é »å‡ºã‚¯ãƒ©ã‚¹ã«æ—©æœŸåæŸã—ã¦ã„ã‚‹

| é …ç›® | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | å¤‰æ›´å¾Œ |
|------|-------------|--------|
| learning_rate | 3e-4 | 1e-4 |

**æ ¹æ‹ **:

- T5ã®æ¨å¥¨å­¦ç¿’ç‡ã¯1e-4ã€œ3e-4
- ä¸å‡è¡¡ãƒ‡ãƒ¼ã‚¿ã§ã¯ä½ã„å­¦ç¿’ç‡ãŒå®‰å®šã™ã‚‹å‚¾å‘

**å®Ÿè£…**: ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã®CONFIGå¤‰æ›´ã®ã¿ï¼ˆ1è¡Œï¼‰

```python
CONFIG = {
    ...
    "learning_rate": 1e-4,  # 3e-4 -> 1e-4
    ...
}
```

**æœŸå¾…åŠ¹æœ**: ã‚ˆã‚Šæ…é‡ãªæœ€é©åŒ–ã§mode collapseç·©å’Œ

---

### Exp2: Top-100çµµæ–‡å­—åˆ¶é™ (v3_top100)

**ä»®èª¬**: 785ç¨®é¡ã¯å¤šã™ãã‚‹ã€‚å­¦ç¿’å¯¾è±¡ã‚’çµã‚‹ã“ã¨ã§å„çµµæ–‡å­—ã®ã‚µãƒ³ãƒ—ãƒ«æ•°ã‚’å¢—åŠ 

| é …ç›® | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | å¤‰æ›´å¾Œ |
|------|-------------|--------|
| çµµæ–‡å­—ç¨®é¡ | 785 | 100 |
| ã‚µãƒ³ãƒ—ãƒ«æ•° | 5,000 | ç´„2,500ã€œ3,500ï¼ˆæ¨å®šï¼‰ |
| 1çµµæ–‡å­—ã‚ãŸã‚Šã‚µãƒ³ãƒ—ãƒ« | ç´„5ä»¶ | ç´„25ã€œ35ä»¶ |

**æ ¹æ‹ **:

- å®Ÿç”¨ä¸Šã‚ˆãä½¿ã‚ã‚Œã‚‹çµµæ–‡å­—ã¯Top-100ç¨‹åº¦
- å­¦ç¿’ãƒ‡ãƒ¼ã‚¿ã®å¯†åº¦ã‚’ä¸Šã’ã‚‹ã“ã¨ã§æ±åŒ–æ€§èƒ½å‘ä¸Š

**å®Ÿè£…**: ãƒãƒ¼ãƒˆãƒ–ãƒƒã‚¯ã«ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚»ãƒ«ã‚’è¿½åŠ 

```python
# Top-100çµµæ–‡å­—ã‚’ç‰¹å®š
top_100_emojis = set(e for e, _ in emoji_counts.most_common(100))
print(f"Top-100 emojis: {len(top_100_emojis)}")

# ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ï¼ˆå…¨çµµæ–‡å­—ãŒTop-100ã«å«ã¾ã‚Œã‚‹ã‚µãƒ³ãƒ—ãƒ«ã®ã¿ï¼‰
filtered_samples = [
    s for s in samples
    if all(e in top_100_emojis for e in s["emoji_string"].split())
]
print(f"Filtered samples: {len(filtered_samples)} / {len(samples)}")

# ãƒ•ã‚£ãƒ«ã‚¿å¾Œã®ã‚µãƒ³ãƒ—ãƒ«ã‚’ä½¿ç”¨
samples = filtered_samples
```

**æœŸå¾…åŠ¹æœ**: å­¦ç¿’å¯¾è±¡ãŒçµã‚‰ã‚Œã€å„çµµæ–‡å­—ã®å­¦ç¿’æ©Ÿä¼šãŒå¢—åŠ 

---

### Exp3: çµ„ã¿åˆã‚ã› (v3_lr1e-4_top100)

**ä»®èª¬**: Exp1ã¨Exp2ã®ç›¸ä¹—åŠ¹æœ

| é …ç›® | å€¤ |
|------|-----|
| learning_rate | 1e-4 |
| çµµæ–‡å­—ç¨®é¡ | Top-100 |

**å®Ÿæ–½æ¡ä»¶**: Exp1ã¾ãŸã¯Exp2ã§æ”¹å–„ãŒè¦‹ã‚‰ã‚ŒãŸå ´åˆ

**å®Ÿè£…**: Exp1 + Exp2ã®å¤‰æ›´ã‚’ä¸¡æ–¹é©ç”¨

---

### Exp4: Focal Loss (v3_focal)

**ä»®èª¬**: ã‚¯ãƒ­ã‚¹ã‚¨ãƒ³ãƒˆãƒ­ãƒ”ãƒ¼ã¯é »å‡ºã‚¯ãƒ©ã‚¹ã«åã‚Šã‚„ã™ã„ã€‚Focal Lossã§ä½é »åº¦ã‚¯ãƒ©ã‚¹ã®å­¦ç¿’ã‚’ä¿ƒé€²

**Focal Lossã®å¼**:

```
FL(p_t) = -Î±_t * (1 - p_t)^Î³ * log(p_t)
```

| ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ | å€¤ | èª¬æ˜ |
|-----------|-----|------|
| Î³ (gamma) | 2.0 | focusing parameterï¼ˆæ¨™æº–å€¤ï¼‰ |
| Î± (alpha) | 1.0 | class weightï¼ˆåˆæœŸã¯å‡ç­‰ï¼‰ |

**æ ¹æ‹ **:

- ç‰©ä½“æ¤œå‡ºï¼ˆRetinaNetï¼‰ã§ã‚¯ãƒ©ã‚¹ä¸å‡è¡¡å•é¡Œã‚’è§£æ±ºã—ãŸæ‰‹æ³•
- ç°¡å˜ãªä¾‹ï¼ˆé«˜ç¢ºç‡ã§æ­£è§£ï¼‰ã®æå¤±ã‚’ä¸‹ã’ã€é›£ã—ã„ä¾‹ã«é›†ä¸­

**å®Ÿè£…**: `src/models/t5_trainer.py`ã«ã‚«ã‚¹ã‚¿ãƒ Trainerã‚’è¿½åŠ 

```python
class FocalLossTrainer(Trainer):
    def __init__(self, gamma: float = 2.0, **kwargs):
        super().__init__(**kwargs)
        self.gamma = gamma

    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):
        labels = inputs.pop("labels")
        outputs = model(**inputs)
        logits = outputs.logits

        # Focal Lossè¨ˆç®—
        ce_loss = F.cross_entropy(
            logits.view(-1, logits.size(-1)),
            labels.view(-1),
            reduction='none',
            ignore_index=-100
        )
        pt = torch.exp(-ce_loss)
        focal_loss = ((1 - pt) ** self.gamma * ce_loss).mean()

        return (focal_loss, outputs) if return_outputs else focal_loss
```

**å®Ÿæ–½æ¡ä»¶**: Exp1-3ã§ååˆ†ãªæ”¹å–„ãŒè¦‹ã‚‰ã‚Œãªã„å ´åˆ

---

## æˆåŠŸåŸºæº–

| æŒ‡æ¨™ | ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ | ç›®æ¨™ | å‚™è€ƒ |
|------|-------------|------|------|
| Average Jaccard | 0.045 | > 0.10 | 2å€ä»¥ä¸Šã®æ”¹å–„ |
| Top5ä»¥å¤–ã®å‡ºåŠ›å‰²åˆ | ã€œ0% | > 30% | å¤šæ§˜æ€§æŒ‡æ¨™ |
| Exact Match | 0% | > 1% | å®Œå…¨ä¸€è‡´ã®å‡ºç¾ |

### å¤šæ§˜æ€§æŒ‡æ¨™ã®è¨ˆç®—æ–¹æ³•

```python
def diversity_ratio(predictions, top_n_emojis):
    """Top-Nçµµæ–‡å­—ä»¥å¤–ã®å‡ºåŠ›å‰²åˆã‚’è¨ˆç®—"""
    total = 0
    non_top_n = 0
    for pred in predictions:
        emojis = pred.split()
        total += len(emojis)
        non_top_n += sum(1 for e in emojis if e not in top_n_emojis)
    return non_top_n / total if total > 0 else 0
```

---

## å®Ÿæ–½é †åº

```
Exp1 (lr1e-4)
    â”‚
    â”œâ”€ æ”¹å–„ã‚ã‚Š â†’ Exp3 (lr1e-4 + top100)
    â”‚
    â””â”€ æ”¹å–„ãªã— â†’ Exp2 (top100)
                      â”‚
                      â”œâ”€ æ”¹å–„ã‚ã‚Š â†’ Exp3
                      â”‚
                      â””â”€ æ”¹å–„ãªã— â†’ Exp4 (focal)
```

**æ¨å®šæ‰€è¦æ™‚é–“**: å„å®Ÿé¨“30åˆ†ã€œ1æ™‚é–“ï¼ˆColab L4 GPUï¼‰

---

## å¿…è¦ãªå®Ÿè£…ã‚¿ã‚¹ã‚¯

| ã‚¿ã‚¹ã‚¯ | å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ« | å„ªå…ˆåº¦ | çŠ¶æ…‹ |
|--------|-------------|--------|------|
| Exp1ç”¨CONFIGå¤‰æ›´ | notebooks/train_t5_colab.py | é«˜ | å®Œäº† |
| Top-100ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã‚»ãƒ«è¿½åŠ  | notebooks/train_t5_colab.py | é«˜ | å®Œäº† |
| FocalLossTrainerå®Ÿè£… | src/models/t5_trainer.py | ä¸­ | å®Œäº† |
| å¤šæ§˜æ€§æŒ‡æ¨™ã®è¿½åŠ  | src/evaluation/metrics.py | ä¸­ | å®Œäº† |

---

## å‚è€ƒæ–‡çŒ®

- [Focal Loss for Dense Object Detection](https://arxiv.org/abs/1708.02002) (Lin et al., 2017)
- [Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer](https://arxiv.org/abs/1910.10683) (Raffel et al., 2019)

---

## é–¢é€£ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆ

- [experiment_v3_5000samples.md](experiment_v3_5000samples.md): v3ãƒ™ãƒ¼ã‚¹ãƒ©ã‚¤ãƒ³ã®å®Ÿé¨“çµæœ
- [experiment_v1_1000samples.md](experiment_v1_1000samples.md): v1ã§ã®å®Ÿé¨“ï¼ˆå®Œå…¨mode collapseï¼‰
- [dataset_generation_v3.md](dataset_generation_v3.md): v3ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®å“è³ªæ”¹å–„
