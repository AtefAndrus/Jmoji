# データセット生成 v3: 品質改善と件数保証

## v3概要

dataset_v2（5,000件）の品質分析から得られた知見を基に、データセット生成パイプラインを改善した。主な変更点は以下の3つ:

1. **事前フィルタ**: 半端な文をClaudeに渡す前に除外
2. **SNS絵文字除去**: Claude出力から絵文字を除去
3. **件数保証**: 目標サンプル数に達するまで生成を継続

---

## 1. dataset_v2の品質分析

### 基本統計

| 項目 | 値 |
|------|-----|
| 総サンプル数 | 4,988件 |
| 目標との差 | -12件（0.24%） |
| 絵文字総数 | 13,599 |
| ユニーク絵文字 | 767種類 |

### 絵文字分布の改善

v1での問題だった✨（キラキラ）の偏り（18.6%）は、プロンプト改善により解消された。

| 順位 | v1 | v2 |
|------|-----|-----|
| 1位 | ✨ 18.6% | 📚 3.6% |
| 2位 | 📚 4.1% | 🎵 3.2% |
| 3位 | 🎉 3.5% | 🏆 2.4% |

### 検出された問題

#### 1. 半端な文（271件、5.4%）

| パターン | 件数 | 例 |
|----------|------|-----|
| truncated | 118 | `『天才・たけしの元気が出るテレビ!` |
| meta_section | 70 | `関連項目 DJ OZMA LISA 脚注...` |
| orphan_close | 44 | `』に応募し、番組の企画として...` |
| no_ending | 39 | `西ドイツの政治 ドイツの軍事史...` |

**原因**: Wikipediaの文分割が不完全で、記事の構造情報や途中で切れた文が混入。

#### 2. SNS変換に絵文字が混入（894件、17.9%）

```text
Original: 太陽コロナは、太陽表面の有効温度よりもはるかに高温である。
SNS:      太陽のコロナって、太陽の表面より圧倒的に熱いんだよね〜🌞 不思議だよなあ
```

Claude Haikuが自発的にSNS風として絵文字を挿入していた。T5の入力に絵文字が混じると、出力との役割が曖昧になる問題があった。

#### 3. API回答の混入（1件）

```text
SNS: 申し訳ありませんが、提供いただいた文章が不完全で、文脈が不明確なため、正確な変換が困難です。
```

元文が断片的すぎてClaudeが変換を拒否し、説明文を出力したケース。

---

## 2. 実装した改善

### 2.1 事前フィルタ（text_preprocessor.py）

```python
def is_complete_sentence(text: str) -> tuple[bool, str]:
    """文として完全かどうかを判定"""
    # メタセクション（Wikipediaの構造情報）
    if re.match(r'^(関連項目|参考文献|外部リンク|脚注|出典|注釈)', text):
        return False, "meta_section"
    # 途中切れ（開き括弧で終わる）
    if re.search(r'[（(「『][^）)」』]{0,30}$', text):
        return False, "truncated"
    # 閉じ括弧で始まる（前の文脈がない）
    if re.match(r'^[」』）)]', text):
        return False, "orphan_close"
    # 句読点なし
    if not re.search(r'[。！？!?」』)]$', text):
        return False, "no_ending"
    return True, ""
```

### 2.2 SNS絵文字除去（dataset_generator.py）

```python
from src.data.text_preprocessor import remove_emojis

# SNS変換後に絵文字を除去
sns_text = client.complete(prompts.SNS_CONVERSION_PROMPT.format(text=sentence)).strip()
sns_text = remove_emojis(sns_text).strip()
```

`emoji.replace_emoji(text, replace="")` を使用して、Claude出力から絵文字を除去。

### 2.3 件数保証（wikipedia_loader.py, dataset_generator.py）

```yaml
# configs/default.yaml
data:
  max_samples: 5000
  buffer_ratio: 1.3  # 30%多く取得
```

- Wikipedia取得時に `max_samples * buffer_ratio` の文を取得
- 生成時に成功件数が `target_count` に達したら終了

### 2.4 フィルタログ

除外された文を `data/outputs/filtered_sentences.jsonl` に記録:

```json
{"reason": "nsfw", "detail": "殺人", "text": "..."}
{"reason": "incomplete", "detail": "meta_section", "text": "関連項目 ..."}
{"reason": "incomplete", "detail": "truncated", "text": "『天才・たけしの..."}
```

---

## 3. 絵文字変換品質の評価

20件のランダムサンプルを評価した結果:

| 評価 | 件数 | 割合 |
|------|------|------|
| 両方良好 | 15 | 75% |
| SNS変換に問題 | 2 | 10% |
| 絵文字選択に問題 | 2 | 10% |
| 両方微妙 | 1 | 5% |

### 良好な例

```text
Original: 1983年の中日クラウンズでは初日6位タイで迎えた2日目...
SNS:      1983年の中日クラウンズ、初日6位タイから2日目に挑んだんだけど...
Emojis:   ⛳ 🏌️ 🎯 😄
```

### 問題のあった例

```text
Original: ボロノフは2018年7月にアイスショー出演のため来日した際に...
Emojis:   🎤 🩸 😢
```

🩸（血）が文脈と無関係。フィギュアスケートの話題なのに誤った絵文字が選択された。

---

## 4. 設定ファイルの変更

```yaml
data:
  output_filename: "dataset_v3.jsonl"
  filter_log_filename: "filtered_sentences.jsonl"
  buffer_ratio: 1.3
  complete_sentence_filter: true
```

---

## 5. コマンドオプション

```bash
# 標準実行（全フィルタ有効）
uv run scripts/generate_dataset.py --config configs/default.yaml

# 非同期モード（高速）
uv run scripts/generate_dataset.py --config configs/default.yaml --async

# フィルタ無効化オプション
uv run scripts/generate_dataset.py --no-complete-filter  # 文完全性フィルタ無効
uv run scripts/generate_dataset.py --no-nsfw-filter      # NSFWフィルタ無効
```

---

## 6. 期待される改善効果

| 項目 | v2 | v3（期待） |
|------|-----|------------|
| 半端な文 | 271件（5.4%） | 0件 |
| SNS内絵文字 | 894件（17.9%） | 0件 |
| API回答混入 | 1件 | 0件 |
| 件数保証 | 4,988件 | 5,000件 |

---

## 7. 今後の課題

1. **絵文字選択の精度向上**: 一部の文脈で無関係な絵文字が選択される問題（約10%）
2. **プロンプトの改善**: より具体的な文脈理解を促すプロンプト設計
3. **データ拡張**: mC4など他のコーパスの追加検討

---

## 8. v3生成結果（2025-12-05）

### v3基本統計

| 項目 | v2 | v3 | 改善 |
|------|-----|-----|------|
| サンプル数 | 4,988 | **5,000** | 件数保証達成 |
| 絵文字総数 | 13,599 | 13,740 | +141 |
| ユニーク絵文字 | 767 | 785 | +18種 |
| 平均絵文字数/サンプル | 2.73 | 2.75 | - |

### 絵文字分布（Top 10）

| 順位 | 絵文字 | 出現数 | 割合 |
|------|--------|--------|------|
| 1 | 🎵 | 511 | 3.72% |
| 2 | 📚 | 482 | 3.51% |
| 3 | 🎉 | 343 | 2.50% |
| 4 | 🎤 | 329 | 2.39% |
| 5 | 🏆 | 321 | 2.34% |
| 6 | 😅 | 293 | 2.13% |
| 7 | 😊 | 284 | 2.07% |
| 8 | ⚽ | 248 | 1.80% |
| 9 | 🏛️ | 216 | 1.57% |
| 10 | 🤔 | 188 | 1.37% |

**✨（キラキラ）**: 28件（0.20%）— v1の18.6%から大幅に改善

### 品質チェック結果

| 問題 | v2 | v3 | 改善率 |
|------|-----|-----|--------|
| 半端な文 | 271件（5.4%） | **0件（0%）** | 100% |
| SNS内絵文字 | 894件（17.9%） | **0件（0%）** | 100% |
| API回答混入 | 1件 | 0件 | 100% |

### フィルタ統計

事前フィルタで除外された文: **380件**

| 理由 | 件数 |
|------|------|
| meta_section | 多数 |
| truncated | 多数 |
| orphan_close | 少数 |

### ランダムサンプル（抜粋）

```text
[1] Original: 1971年(昭和46年)7月 - 体育館竣工式挙行。
    SNS:      1971年（昭和46年）7月に体育館が完成して、竣工式をやったんだよね〜
    Emojis:   🏛️ 🎉 📅

[2] Original: こうして「段ボールで築城する」という前代未聞の試みが実施される。
    SNS:      こうして「段ボールで城を作る」っていう、前代未聞の試みが実行されることになったわけ。
    Emojis:   🏰 📦 😄

[3] Original: 連射パッドが使えないので自力で行なわなければいけない。
    SNS:      連射パッド使えないから自分でやんなきゃいけないんだよね。
    Emojis:   🎮 😅
```

### 結論

**v3は学習に使用可能な品質**。全ての既知問題が解消され、絵文字分布も均一化された。

次のステップ: T5学習でmode collapseが解消されるか検証。

---

## 9. 運用ルール

### シード管理

データセットごとにシード（`random_seed`）を変更する運用とする。

| バージョン | seed | 備考 |
|------------|------|------|
| v1 | 42 | 初期実験（mode collapse） |
| v2 | 42 | 品質問題あり |
| v3 | 42 | 品質改善版（学習用） |
| v4以降 | 43, 44, ... | バージョンごとに変更 |

**理由**: 同じseedでは同じ文が同じ順番で出てくるため、データセット間の独立性が低下する。

---

## 10. v4データセット生成（2025-12-19）

v4データセットは教師モデル移行後に生成された大規模データセット。

### v4概要

| 項目 | 値 |
|------|-----|
| 教師モデル | Qwen3-235B-A22B（OpenRouter経由） |
| サンプル数 | 20,000件 |
| seed | 43 |
| フィルタ除外 | 1,309件（6.5%） |

### 移行の理由

- コスト削減: Claude Haiku 4.5の約1/3
- 品質維持: Shisa.AI推奨設定で100%成功率
- 日本語対応: 良好な日本語生成品質

### 詳細

教師モデル移行の経緯と設定詳細は [teacher_model_migration.md](../teacher_model_migration.md) を参照。
