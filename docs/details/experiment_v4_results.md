# 実験記録: v4データセットでの学習実験

## 概要

本ドキュメントは、v4データセット（20,000件、Qwen3-235B-A22B生成）での学習実験の結果を記録する。

**実験期間**: 2025-12-23 〜 2025-12-24
**実験環境**: Google Colab Pro（NVIDIA A100-SXM4-40GB）
**目標**: Jaccard 0.10以上、多様性 30%以上

---

## 実験結果サマリー

| # | 実験名 | データ件数 | 件/絵文字 | Jaccard | 多様性 | 状態 |
|---|--------|-----------|-----------|---------|--------|------|
| 1 | v4_lr1e-4 | 20,000 | 15 | 0.066 | 19% | 完了 |
| 2 | v4_top100 | 4,237 | 42 | 0.120 | 21% | 完了 |
| 3 | v4_focal_top100 | 4,237 | 42 | 0.115 | **25%** | 完了 |
| 4 | v4_top50 | 1,337 | 27 | **0.165** | 21% | 完了 |

**最良結果**: v4_top50（Jaccard 0.165、精度最良）、v4_focal_top100（多様性25%、多様性最良）

---

## 各実験の詳細

### Exp1: v4_lr1e-4（全件使用）

**目的**: v4データセット全件での学習効果を確認

| 設定 | 値 |
|------|-----|
| learning_rate | 1e-4 |
| データ | 20,000件（全件使用） |
| 絵文字種類 | 1,300種 |
| 件/絵文字 | 約15件 |

#### 結果

| 指標 | v3_top100 | v4_lr1e-4 | 変化 |
|------|-----------|-----------|------|
| Avg Jaccard | 0.058 | 0.066 | +14% |
| Micro F1 | 0.094 | 0.112 | +19% |
| 多様性 | 20% | 19% | -5% |
| ユニーク絵文字 | - | 45 | - |

#### 考察

- データ量4倍でJaccard +14%改善
- ただし絵文字種類が1,300種と多く、件/絵文字が15件と低密度
- v3_top100（22件/絵文字）より低密度だが、データ量の効果で上回った

---

### Exp2: v4_top100（Top-100絵文字制限）

**目的**: データ密度を高めて学習効率を向上

| 設定 | 値 |
|------|-----|
| learning_rate | 3e-4（デフォルト） |
| データ | 4,237件（Top-100絵文字のみ） |
| 絵文字種類 | 100種 |
| 件/絵文字 | 約42件 |

#### 結果

| 指標 | v3_top100 | v4_top100 | 変化 |
|------|-----------|-----------|------|
| Avg Jaccard | 0.058 | **0.120** | **+106%** |
| Micro F1 | 0.094 | **0.194** | **+106%** |
| Avg Precision | - | 0.223 | - |
| Avg Recall | - | 0.176 | - |
| 多様性 | 20% | 21% | +5% |
| ユニーク絵文字 | - | 34 | - |
| Eval Loss | 4.714 | 4.660 | -1% |

#### 考察

- **Jaccard 0.12達成**（目標0.10を超過）
- データ密度2倍（22件→42件）でJaccardも2倍以上改善
- **データ密度仮説の強力な実証**
- 多様性は21%で横ばい（目標30%には未達）

---

### Exp3: v4_focal_top100（Focal Loss + Top-100）

**目的**: Focal Lossで低頻度絵文字の学習を促進し、多様性を改善

| 設定 | 値 |
|------|-----|
| learning_rate | 3e-4（デフォルト） |
| focal_gamma | 2.0 |
| label_smoothing | 0.0（Focal Lossと併用しない） |
| データ | 4,237件（Top-100絵文字のみ） |
| 絵文字種類 | 100種 |
| 件/絵文字 | 約42件 |

#### 結果

| 指標 | v4_top100 | v4_focal_top100 | 変化 |
|------|-----------|-----------------|------|
| Avg Jaccard | 0.120 | 0.115 | -3.5% |
| Micro F1 | 0.194 | 0.189 | -2.6% |
| Avg Precision | 0.223 | 0.217 | -2.7% |
| Avg Recall | 0.176 | 0.172 | -2.3% |
| 多様性 | 21% | **25%** | **+19%** |
| ユニーク絵文字 | 34 | 34 | - |
| Eval Loss | 4.660 | **3.450** | **-26%** |

#### 考察

- **多様性改善に成功**: 21%→25%（+19%）で目標30%に接近
- **Eval Loss大幅改善**: -26%で学習収束が改善
- **Jaccardは微減**: -3.5%でFocal Lossは精度向上には寄与せず
- Exact Match 0%（v3_focal_top100では0.46%達成）
- 📚、😊、🔥 の過剰生成傾向は継続（soft mode collapse）

---

### Exp4: v4_top50（Top-50絵文字制限）

**目的**: 絵文字種類をさらに制限し、精度向上を検証

| 設定 | 値 |
|------|-----|
| learning_rate | 3e-4（デフォルト） |
| データ | 1,337件（Top-50絵文字のみ） |
| 絵文字種類 | 50種 |
| 件/絵文字 | 約27件 |

注: 期待した84件/絵文字ではなく27件。top50絵文字のみを含むサンプルがv4データセットでは少なかった。

#### 結果

| 指標 | v4_top100 | v4_top50 | 変化 |
|------|-----------|----------|------|
| Avg Jaccard | 0.120 | **0.165** | **+38%** |
| Micro F1 | 0.194 | **0.269** | **+38%** |
| Avg Precision | 0.223 | 0.313 | +40% |
| Avg Recall | 0.176 | 0.234 | +33% |
| 多様性 | 21% | 21% | - |
| ユニーク絵文字 | 34 | 16 | -53% |
| Eval Loss | 4.660 | 4.195 | -10% |

#### 考察

- **Jaccard 0.165達成**: 目標0.15+を超過、これまでで最高精度
- **絵文字種類削減の効果**: 100→50種で精度+38%向上
- **多様性は改善せず**: 21%で横ばい
- **出力多様性低下**: ユニーク絵文字16種（50種中32%のみ使用）
- 📚、😊、🇯🇵、🎉 が頻出（soft mode collapse継続）

---

## 予測サンプル分析

### 良好な例

| 入力 | 正解 | 予測 | Jaccard |
|------|------|------|---------|
| 帰国子女や留学生のための選抜... | 📚🌍🇯🇵😊🎓 | 📚📚🎵😊😊 | 0.33 |
| 日本語の地図だと... | 🗺️📍😊🇯🇵🔍 | 🏛️📚🇯🇵😊😊 | 0.29 |
| 試合、めっちゃ策こらしてた... | ⚽🔥💪😊👏 | 😊👏🤔😊🎉 | 0.29 |

### 課題のある例

| 入力 | 正解 | 予測 | 問題点 |
|------|------|------|--------|
| その頭脳、本人曰く... | 🧠💡😲🤓👏 | 😊😊😊🇯🇵🤝 | 😊の過剰生成 |
| インダクタンスの値や... | 🔧⚙️📡🧠💡 | 🎵😊🇯🇵🤝😊 | 技術文脈の理解不足 |

### 傾向

- 😊、🇯🇵 が頻出（soft mode collapse傾向継続）
- 出力ユニーク絵文字は34種（100種中）
- Exact Match 0%（完全一致なし）

---

## 総合分析

### 実験結果の全体像（v3〜v4）

| 実験 | データ件数 | 件/絵文字 | Jaccard | 多様性 |
|------|-----------|-----------|---------|--------|
| v3_baseline | 5,000 | 6 | 0.045 | ~0% |
| v3_top100 | 2,187 | 22 | 0.058 | 20% |
| v4_lr1e-4 | 20,000 | 15 | 0.066 | 19% |
| v4_top100 | 4,237 | 42 | 0.120 | 21% |
| v4_focal_top100 | 4,237 | 42 | 0.115 | **25%** |
| **v4_top50** | 1,337 | 27 | **0.165** | 21% |

### 主要な知見

1. **絵文字種類削減が精度向上に効果的**
   - 100種→50種でJaccard +38%（0.120→0.165）
   - 件/絵文字が減少（42→27）しても絵文字種類削減の効果が上回る

2. **top50フィルタ率の低下**
   - v4_top100: 20,000件中4,237件（21.2%）
   - v4_top50: 20,000件中1,337件（6.7%）
   - Qwen3がより多様な絵文字を生成する傾向

3. **Focal Lossの効果**
   - 多様性改善に有効（21%→25%、+19%）
   - Jaccard改善には寄与せず（むしろ-3.5%）
   - Loss収束は大幅改善（-26%）

4. **精度と多様性のトレードオフ**
   - v4_top50: Jaccard最高（0.165）だが多様性横ばい（21%）
   - v4_focal_top100: 多様性最高（25%）だがJaccardやや低い（0.115）

### 残課題

| 課題 | 詳細 | 対策案 |
|------|------|--------|
| 多様性不足 | 21〜25%（目標30%） | Focal Loss + top50の組み合わせ |
| soft mode collapse | 😊📚🇯🇵🎉の過剰生成 | 低頻度絵文字の重み付け強化 |
| Exact Match 0% | 完全一致なし | さらなるデータ密度向上 |
| 出力多様性低下 | top50で16種のみ使用 | Focal Lossとの併用 |

---

## 次のステップ

### 短期（推奨）

| アクション | 理由 | 期待効果 |
|-----------|------|----------|
| **v4_focal_top50** | top50 + Focal Lossの組み合わせ | Jaccard 0.15+維持、多様性25%+ |

### 中期

| アクション | 理由 | 期待効果 |
|-----------|------|----------|
| 人手評価の実施 | Jaccard以外の品質確認 | 定性評価 |
| データ生成時のtop50優先 | フィルタ率向上（現状6.7%） | より多くの学習データ |

---

## 実験ログの保存場所

```
outputs/experiments/
├── v4_lr1e-4_20251223/
│   ├── config.yaml
│   ├── train_log.csv
│   ├── eval_metrics.json
│   ├── predictions_sample.jsonl
│   └── summary.md
├── v4_top100_20251224/
│   ├── config.yaml
│   ├── train_log.csv
│   ├── eval_metrics.json
│   ├── predictions_sample.jsonl
│   └── summary.md
├── v4_focal_top100_20251224/
│   ├── config.yaml
│   ├── train_log.csv
│   ├── eval_metrics.json
│   ├── predictions_sample.jsonl
│   └── summary.md
└── v4_top50_20251224/
    ├── config.yaml
    ├── train_log.csv
    ├── eval_metrics.json
    ├── predictions_sample.jsonl
    └── summary.md
```

---

## 関連ドキュメント

- [experiment_v3_improvements.md](experiment_v3_improvements.md): v3での学習改善実験
- [teacher_model_migration.md](teacher_model_migration.md): 教師モデル移行（Qwen3への変更）
- [dataset_generation_v3.md](dataset_generation_v3.md): データセット生成の品質改善
