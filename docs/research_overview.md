# 研究概要

## 1. テーマ

知識蒸留を用いた日本語-絵文字翻訳モデルの開発

## 2. 背景と目的

現代のテキストコミュニケーションにおいて、絵文字は感情や文脈、話し手のスタンスをコンパクトに伝える重要なメディアです。しかし、以下の課題が存在します:

- 日本語テキストから複数の絵文字列を直接生成するモデルがほとんど存在しない
- 十分な規模と品質を備えた日本語のテキスト–絵文字並列データセットがない

本研究では、LLM（Qwen3-235B-A22B）を教師モデルとして用い、日本語テキストと絵文字列からなる疑似対訳データセットを構築し、より軽量な翻訳モデル（学生モデル）へ知識蒸留を行います。

> **Note**: v1〜v3データセットはClaude Haiku 4.5で生成。v4以降はQwen3-235B-A22Bを使用。移行理由は [teacher_model_migration.md](details/teacher_model_migration.md) を参照。

## 3. タスク定義

### 入力

- 日本語テキスト（SNS風の短文〜中程度長さ）
- 目安: 10〜100トークン程度の一文または一発話

### 出力

- 文全体の意味・ニュアンス・トーンを表現する絵文字列
- 個数: 1〜5個
- フォーマット: 空白区切り（例: `😂 😢 🙏`）

### タスクの位置づけ

- 日本語自然文から絵文字列への「翻訳タスク」（Text-to-Emoji）
- 正解は一意に定まらないが、教師LLMが生成した絵文字列を正解ラベルとする

## 4. 手法

### 4.1 データセット構築（広義の知識蒸留）

#### ベースコーパス

| コーパス | 用途 | ライセンス | 規模 |
|---------|------|-----------|------|
| 日本語Wikipedia | 主 | CC BY-SA 3.0 | 5,000ペア（小規模実験） |
| mC4 Japanese subset | 将来拡張 | ODC-BY | 未実装 |

**注**: 当初1,000ペアで実験したが、絵文字分布の偏り（✨が18.6%を占める）によりmode collapseが発生したため、5,000ペアに拡大しプロンプトを改善した。将来的にはmC4を追加してデータ多様性を向上させても良いと考えている。

#### 処理フロー

```text
Wikipedia/mC4 文
    ↓
[教師LLM] SNS風文体に変換
    ↓
SNS風テキスト
    ↓
[教師LLM] 絵文字生成
    ↓
(テキスト, 絵文字列) ペア
```

教師LLM: Qwen3-235B-A22B（v4以降）/ Claude Haiku 4.5（v1〜v3）

#### 絵文字対象範囲

- Emoji 16.0準拠（2024年9月リリース、約3,790種類）
- 肌色バリアント: 基本絵文字に統合（👋🏻 → 👋）
- ZWJシーケンス: 単一絵文字として扱う（👨‍👩‍👧 = 1単位）

#### 絵文字バランスの課題と対策

初期実験（1,000ペア）で以下の問題が判明:

- ✨（キラキラ）が全絵文字の18.6%を占め、2位（📚: 4.1%）の4.5倍
- T5モデルが✨のみを出力するmode collapseが発生
- label_smoothing等の学習側の対策では解決せず

**対策**:

1. プロンプトで✨の使用を禁止
2. 具体的な内容（スポーツ、音楽等）に関連する絵文字を優先するよう指示
3. データセットを5,000ペアに拡大

#### データセット品質改善（v3）

5,000ペアのデータセット（v2）の品質分析から、以下の追加対策を実施:

1. **事前フィルタ**: 半端な文（メタ情報、途中切れ等）をClaudeに渡す前に除外
2. **SNS絵文字除去**: Claude出力から絵文字を除去し、T5入力をクリーンに
3. **件数保証**: 目標サンプル数に達するまで生成を継続

詳細は [dataset_generation_v3.md](details/datasets/generation_v3.md) を参照。

### 4.2 モデル構成

#### 主モデル: 日本語T5

- ベース: `sonoisa/t5-base-japanese`（222Mパラメータ）
- アーキテクチャ: encoder-decoder Transformer
- 学習タスク: 次トークン予測に基づくテキスト生成

#### ベースライン: BERTマルチラベル分類

- ベース: `tohoku-nlp/bert-base-japanese-v3`
- タスク: 頻出絵文字Top-100のマルチラベル分類

### 4.3 学習設定

| 項目 | 設定 |
|------|------|
| 損失関数 | クロスエントロピー |
| 最適化 | AdamW |
| スケジューリング | warmup + 減衰 |
| 早期終了 | 検証セットの損失/F1で判定 |

## 5. 評価方法

### 主要指標

#### **Jaccard類似度**

```text
J(A, B) = |A ∩ B| / |A ∪ B|
```

- 絵文字の順序に依存しない
- 0〜1の範囲で解釈が直感的
- 部分一致を適切に評価可能

### 補助指標

- 絵文字集合ベースの Precision / Recall / F1
- 完全一致率（Exact Match Rate）
- 出力長分布の比較

### 人手評価

- 評価対象: 50〜100文
- 評価者: 3〜5名の日本語話者
- 評価項目:
  - 意味的一致度（0〜4段階）
  - 自然さ（0〜4段階）
  - 誤解を招く可能性（Yes/No）

## 6. 進捗状況

詳細な進捗管理は [status.md](status.md) を参照。

### 完了済み

- タスク仕様の確定
- 教師LLMプロンプトの設計・試行
- データセット構築（v1〜v4、最大20,000件）
- T5モデル学習・チューニング
- 自動評価指標の整備（Jaccard、F1等）
- LLM-as-a-Judge評価
- 人手評価パイロット（20件）

### 進行中

- 人手評価の拡大（50〜100件）
- エラー分析
- 論文・発表資料作成

## 7. 先行研究との差異

| 観点 | 既存研究 | 本研究 |
|------|---------|--------|
| タスク | 感情ラベルとして1絵文字を予測 | 複数絵文字列への翻訳 |
| 言語 | 英語中心 | 日本語特化 |
| データ | SNS直接収集 or 英語合成 | 日本語LLMによる疑似対訳生成 |

## 8. 想定される課題

1. **教師LLM由来のバイアス**: 特定絵文字への偏り → ダウンサンプリングで対応
2. **定量評価の難しさ**: 正解が一意でない → 複数指標 + 人手評価で対応
3. **教師LLMのノイズ**: 無関係な絵文字の混入 → 目視確認 + フィルタリング
4. **Mode Collapse**: 頻出絵文字への偏り → データ側（✨禁止）とモデル側（Focal Loss等）の両面対策が必要。詳細は実験記録を参照:
   - [v1実験](details/experiments/v1_1000samples.md): 完全mode collapse（✨のみ出力）
   - [v3実験](details/experiments/v3_5000samples.md): soft mode collapse（Top5絵文字に偏り）

## 参考文献

- Eisner et al. (2016). emoji2vec: Learning Emoji Representations from their Description
- Peng & Zhao (2021). Seq2Emoji: A hybrid sequence generation model for short text emoji prediction
- Peng et al. (2023). EmojiLM: Modeling the new emoji language
